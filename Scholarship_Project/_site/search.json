[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Natural Bridges National Monument Preservation",
    "section": "",
    "text": "Natural Bridges National Monument\n\n\n\nhttps://cdn.britannica.com/08/117908-050-D75717AE/Owachomo-Bridge-Natural-Bridges-National-Monument-Utah.jpg\n\n\n\nWhat is the Natural Bridges National Monument?1\n\nVisit the Official Website!\nBrief Description\nNatural Bridges National Monument is situated 43 miles west of Blanding in San Juan County, Utah, encompassing 7,636.88 acres. The county, the largest in Utah, spans 7,884 square miles within the Colorado Plateau, with elevations ranging from 4,200 to 10,000 feet and receiving only 13 inches of annual precipitation. The park’s landscape includes desert canyons and forested mountains.\nHistorically, the area was first inhabited during the Archaic period (7000 BC to AD 500) by hunter-gatherers, with later occupations by the ancestors of the Puebloan people for farming around AD 700. Subsequent migrations included those from Mesa Verde in the 1200s. By the 1300s, Ancestral Puebloans moved south, followed by Navajos and Paiutes. The site’s significance grew after prospector Cass Hite discovered the bridges in 1883, leading to its establishment as Utah’s first national monument in 1908 by President Theodore Roosevelt. The park features three major natural bridges—Sipapu, Kachina, and Owachomo—each representing different stages of geological development, with names reflecting the region’s Puebloan heritage and culture.\nWhy is it unique?\nNatural Bridges National Monument is unique for having three large natural bridges in close proximity. It also contains significant prehistoric structures and archeological sites with well-preserved wooden features, offering valuable insights into Ancestral Puebloan history on the Colorado Plateau. The park is internationally recognized for its exceptional night sky, being the first designated International Dark Sky Park. Additionally, its deep, moist canyons and diverse ecosystems have been preserved in their natural state due to a long history of protection.\n\n\n\n\nReferences\n\n1. National Park Service. Foundation document. Natural Bridges National Monument (2018)."
  },
  {
    "objectID": "cleaning.html",
    "href": "cleaning.html",
    "title": "Dataset Cleaning",
    "section": "",
    "text": "Import Module\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport xml.etree.ElementTree as ET\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.max_columns', None)\npd.set_option('display.precision', 10)"
  },
  {
    "objectID": "cleaning.html#clean-data-provided",
    "href": "cleaning.html#clean-data-provided",
    "title": "Dataset Cleaning",
    "section": "Clean Data (Provided)",
    "text": "Clean Data (Provided)\nThe clean data seems to have filtered out many columns and rows. In order to figure out what was filtered, I impolemented a few filters on the original dataset to see if I could get the same shape as the clean data.\n\nFilter columns\nFilter years 2021~2024\n\n\n\nImport Clean Data\nclean_df = pd.read_csv('../data/nearterm_data_2020-2024.csv')\n\nprint(\"How does the clean dataset look like?\")\nclean_df.head()\n\n\nHow does the clean dataset look like?\n\n\n\n\n\n\n\n\n\nlong\nlat\nyear\nTimePeriod\nRCP\nscenario\ntreecanopy\nAnn_Herb\nBare\nHerb\nLitter\nShrub\nDrySoilDays_Summer_whole\nEvap_Summer\nExtremeShortTermDryStress_Summer_whole\nFrostDays_Winter\nNonDrySWA_Summer_whole\nPPT_Winter\nPPT_Summer\nPPT_Annual\nT_Winter\nT_Summer\nT_Annual\nTmax_Summer\nTmin_Winter\nVWC_Winter_whole\nVWC_Spring_whole\nVWC_Summer_whole\nVWC_Fall_whole\n\n\n\n\n0\n-110.0472\n37.60413\n2021\nNT\n4.5\nsc22\n0\n0\n84\n5\n11\n7\nNaN\nNaN\nNaN\nNaN\nNaN\n5.94\n6.37\n6.37\n1.6303330\n24.50402\n24.50402\n36.89\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1\n-110.0472\n37.60413\n2021\nNT\n4.5\nsc22\n0\n0\n84\n5\n11\n7\n0.0\n3.2422296149\n36.314\n73.0\n0.0929865127\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n-12.77\n0.1146518092\n0.0787639891\n0.0435142642\n0.0512810069\n\n\n2\n-110.0472\n37.60413\n2021\nNT\n4.5\nsc23\n0\n0\n84\n5\n11\n7\nNaN\nNaN\nNaN\nNaN\nNaN\n6.44\n3.09\n3.09\n1.3890560\n24.11043\n24.11043\n37.95\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n3\n-110.0472\n37.60413\n2021\nNT\n4.5\nsc23\n0\n0\n84\n5\n11\n7\n0.0\n2.4016114656\n36.510\n71.0\n0.0001057892\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n-18.96\n0.1302210687\n0.0964121637\n0.0412322081\n0.0922413330\n\n\n4\n-110.0472\n37.60413\n2021\nNT\n4.5\nsc24\n0\n0\n84\n5\n11\n7\nNaN\nNaN\nNaN\nNaN\nNaN\n5.35\n5.32\n6.87\n-0.3343889\n25.54266\n10.31321\n37.74\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\n\nImport Raw Data and Filter\ndf = pd.read_csv('../data/NABR_ClimExposure', delimiter=' ')\nclean_m = df[(df['year'] &gt;= 2021) & (df['year'] &lt;= 2024)]\nclean_m = clean_m.loc[:, clean_m.columns.isin(list(clean_df.columns))]\n\nprint(\"Given Clean Dataset shape : \", clean_df.shape)\nprint(\"Filtered Original Dataset shape : \", clean_m.shape)\n\n\nGiven Clean Dataset shape :  (55802, 29)\nFiltered Original Dataset shape :  (55802, 29)"
  },
  {
    "objectID": "cleaning.html#conclusion",
    "href": "cleaning.html#conclusion",
    "title": "Dataset Cleaning",
    "section": "Conclusion",
    "text": "Conclusion\nSince the clean data was adding two filters to the original dataset, I decided to clean the original dataset to extract as much information as possible."
  },
  {
    "objectID": "cleaning.html#finding-patterns",
    "href": "cleaning.html#finding-patterns",
    "title": "Dataset Cleaning",
    "section": "Finding Patterns",
    "text": "Finding Patterns\nFirst we will try to find a pattern in how to clean the dataset. What is the unique identity for each row?\nBy grouping vegetation, longitude, latitude, year, and scenario, we know that this isn’t enough to get a unique row. Lets subset one combination to see what rows are in the given combination.\n\n\nGroup Datasets\nnumber_test = df.groupby(['veg','long','lat','year','scenario']).size().reset_index()\nnumber_test.rename({0:'Size'},axis=1,inplace=True)\nnumber_test[number_test['Size'] &gt; 2].head()\n\n\n\n\n\n\n\n\n\nveg\nlong\nlat\nyear\nscenario\nSize\n\n\n\n\n1\nForest\n-110.0348\n37.59067\n1981\nsc1\n5\n\n\n3\nForest\n-110.0348\n37.59067\n1983\nsc1\n5\n\n\n5\nForest\n-110.0348\n37.59067\n1985\nsc1\n5\n\n\n7\nForest\n-110.0348\n37.59067\n1987\nsc1\n5\n\n\n9\nForest\n-110.0348\n37.59067\n1989\nsc1\n5"
  },
  {
    "objectID": "cleaning.html#subset-examination",
    "href": "cleaning.html#subset-examination",
    "title": "Dataset Cleaning",
    "section": "Subset Examination",
    "text": "Subset Examination\nBy looking at the subset of a dataset below, we can see a few interesting points about this dataset\n\nIssue 1\nIt seems like there are many duplicates but no rows are erased when erasing duplicates Why?\n\nFor the first four rows, all the data seem to be duplicates. What’s different?\n\nThe T_Annual and PPT_Annual seem to be different when all other features are the same.\nT_Annual and PPT_Annual seem to be one of the season measurements.\nA standard of unique rows must be defined for meaningful analysis.\n\n\n\n\nSolution 1\n\nRemove T_Annual PPT_Annual columns\nRemove duplicates\nFind the sum of seasonal percipitation and re-define PPT_Annual\nFind the average of seasonal temperatures and re-define T_Annual\n\n\n\nData Subset of one specific identifier\ndf[(df['veg'] == 'Forest') & (df['year'] == 1981) & (df['long'] == -110.0348) & (df['lat'] == 37.59067) & (df['scenario'] == 'sc1')]\n\n\n\n\n\n\n\n\n\nPark\nlong\nlat\nveg\nyear\nTimePeriod\nRCP\nscenario\ntreecanopy\nAnn_Herb\nBare\nHerb\nLitter\nShrub\nEl\nSa\nCl\nRF\nRL\nSlope\nE\nS\nT_P_Corr\nDrySoilDays_Winter_top50\nDrySoilDays_Spring_top50\nDrySoilDays_Summer_top50\nDrySoilDays_Fall_top50\nDrySoilDays_Winter_whole\nDrySoilDays_Spring_whole\nDrySoilDays_Summer_whole\nDrySoilDays_Fall_whole\nEvap_Winter\nEvap_Spring\nEvap_Summer\nEvap_Fall\nExtremeShortTermDryStress_Winter_top50\nExtremeShortTermDryStress_Spring_top50\nExtremeShortTermDryStress_Summer_top50\nExtremeShortTermDryStress_Fall_top50\nExtremeShortTermDryStress_Winter_whole\nExtremeShortTermDryStress_Spring_whole\nExtremeShortTermDryStress_Summer_whole\nExtremeShortTermDryStress_Fall_whole\nFrostDays_Winter\nFrostDays_Spring\nFrostDays_Summer\nFrostDays_Fall\nNonDrySWA_Winter_top50\nNonDrySWA_Spring_top50\nNonDrySWA_Summer_top50\nNonDrySWA_Fall_top50\nNonDrySWA_Winter_whole\nNonDrySWA_Spring_whole\nNonDrySWA_Summer_whole\nNonDrySWA_Fall_whole\nPET_Winter\nPET_Spring\nPET_Summer\nPET_Fall\nPPT_Winter\nPPT_Spring\nPPT_Summer\nPPT_Fall\nPPT_Annual\nSemiDryDuration_Annual_top50\nSemiDryDuration_Annual_whole\nSWA_Winter_top50\nSWA_Spring_top50\nSWA_Summer_top50\nSWA_Fall_top50\nSWA_Winter_whole\nSWA_Spring_whole\nSWA_Summer_whole\nSWA_Fall_whole\nT_Winter\nT_Spring\nT_Summer\nT_Fall\nT_Annual\nTmax_Winter\nTmax_Spring\nTmax_Summer\nTmax_Fall\nTmin_Winter\nTmin_Spring\nTmin_Summer\nTmin_Fall\nTransp_Winter\nTransp_Spring\nTransp_Summer\nTransp_Fall\nVWC_Winter_top50\nVWC_Spring_top50\nVWC_Summer_top50\nVWC_Fall_top50\nVWC_Winter_whole\nVWC_Spring_whole\nVWC_Summer_whole\nVWC_Fall_whole\nWetSoilDays_Winter_top50\nWetSoilDays_Spring_top50\nWetSoilDays_Summer_top50\nWetSoilDays_Fall_top50\nWetSoilDays_Winter_whole\nWetSoilDays_Spring_whole\nWetSoilDays_Summer_whole\nWetSoilDays_Fall_whole\n\n\n\n\n106077\nNABR\n-110.0348\n37.59067\nForest\n1981\nHist\nhistorical\nsc1\n0\n0\n47\n10\n19\n19\n1792.537\n72.9846\n8.094261\n2.230278\n65.21617\n634.6172\n-1960.326\n-9690.729\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.37\n10.16\n9.69\n12.45\n9.69\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n3.393333\n10.47446\n23.1087\n11.46374\n3.393333\n16.95\n28.05\n37.45\n29.55\nNaN\nNaN\nNaN\nNaN\n0.1318164\n5.268698\n4.032515\n2.26957\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n106078\nNABR\n-110.0348\n37.59067\nForest\n1981\nHist\nhistorical\nsc1\n0\n0\n47\n10\n19\n19\n1792.537\n72.9846\n8.094261\n2.230278\n65.21617\n634.6172\n-1960.326\n-9690.729\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.37\n10.16\n9.69\n12.45\n9.69\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n3.393333\n10.47446\n23.1087\n11.46374\n23.108700\n16.95\n28.05\n37.45\n29.55\nNaN\nNaN\nNaN\nNaN\n0.1318164\n5.268698\n4.032515\n2.26957\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n106079\nNABR\n-110.0348\n37.59067\nForest\n1981\nHist\nhistorical\nsc1\n0\n0\n47\n10\n19\n19\n1792.537\n72.9846\n8.094261\n2.230278\n65.21617\n634.6172\n-1960.326\n-9690.729\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.37\n10.16\n9.69\n12.45\n2.37\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n3.393333\n10.47446\n23.1087\n11.46374\n3.393333\n16.95\n28.05\n37.45\n29.55\nNaN\nNaN\nNaN\nNaN\n0.1318164\n5.268698\n4.032515\n2.26957\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n106080\nNABR\n-110.0348\n37.59067\nForest\n1981\nHist\nhistorical\nsc1\n0\n0\n47\n10\n19\n19\n1792.537\n72.9846\n8.094261\n2.230278\n65.21617\n634.6172\n-1960.326\n-9690.729\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.37\n10.16\n9.69\n12.45\n2.37\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n3.393333\n10.47446\n23.1087\n11.46374\n23.108700\n16.95\n28.05\n37.45\n29.55\nNaN\nNaN\nNaN\nNaN\n0.1318164\n5.268698\n4.032515\n2.26957\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n106081\nNABR\n-110.0348\n37.59067\nForest\n1981\nHist\nhistorical\nsc1\n0\n0\n47\n10\n19\n19\n1792.537\n72.9846\n8.094261\n2.230278\n65.21617\n634.6172\n-1960.326\n-9690.729\n0.3326521\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.308474\n6.044908\n5.147714\n4.197853\nNaN\n24.52\n35.96\nNaN\nNaN\n24.52\n35.96\nNaN\n74.0\n26.0\n0.0\n13.0\n1.667453\n2.089958\n0.03898182\n3.199576\n1.876374\n2.415431\n0.03898184\n3.740458\n3.187145\n29.85291\n47.89414\n15.6124\nNaN\nNaN\nNaN\nNaN\nNaN\n11.0\n11.0\n1.667453\n2.089958\n0.03898182\n3.199576\n1.876374\n2.415431\n0.03898184\n3.740458\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n-9.35\n-5.55\n0.95\n-7.25\nNaN\nNaN\nNaN\nNaN\n0.0835052\n0.09223872\n0.04992899\n0.115007\n0.07972316\n0.08898326\n0.04818989\n0.1116202\n90.0\n73.0\n14.0\n89.0\n90.0\n73.0\n14.0\n89.0\n\n\n\n\n\n\n\n\n\nData Cleaning 1\n# Columns to exclude\ncols_to_exclude = ['PPT_Annual', 'T_Annual']\n\n# Create a boolean mask for columns to keep\nmask = df.columns.isin(cols_to_exclude)\n\n# Use loc to select all rows and only the columns not in the mask\nnew_df = df.loc[:, ~mask]\n\ntest = new_df.drop_duplicates()\n\nnumber = test.groupby(['veg','year','long','lat','scenario']).size().reset_index()\nnumber.rename({0:'Size'},axis=1,inplace=True)\n\n# number[number['Size'] &gt; 2]\n\ntest['PPT_Annual'] = test['PPT_Winter'] + test['PPT_Spring'] + test['PPT_Summer'] + test['PPT_Fall']\ntest['T_Annual'] = (test['T_Winter'] + test['T_Spring'] + test['T_Summer'] + test['T_Fall'])/4\n\n\n\n\nIssue 2\nMissing Column values as if extracted by two different sources at the same site\n\nAlthough the so called “identifiers” that I defined were the same, a the value of a group of columns were stored in row A and another group of columns were stored in row B.\n\nRow A and Row B have identical identifiers.\nWhen a column has a value in row A, row B has a null value in the same column\nThe RL column (Depth of Restriction Layer) is slightly different for the two identifiers (Same to fifth decimal point)\nSince the RL was similar, I was willing to sacrifice the fifth decimal point precision for ease of analysis.\n\n\n\n\nSolution 2\n\nRemove RL column but store if with the identifiers\nGroup by the identifiers and fine the average RL.\nWith the original dataset with RL removed, Merge the two rows together vertically so that the null values and data points for identical identifiers merge together.\njoin the average RL and original dataset with identifiers as the joinint key\n\n\n\nBefore cleaning\ntest.head(10)\n\n\n\n\n\n\n\n\n\nPark\nlong\nlat\nveg\nyear\nTimePeriod\nRCP\nscenario\ntreecanopy\nAnn_Herb\nBare\nHerb\nLitter\nShrub\nEl\nSa\nCl\nRF\nRL\nSlope\nE\nS\nT_P_Corr\nDrySoilDays_Winter_top50\nDrySoilDays_Spring_top50\nDrySoilDays_Summer_top50\nDrySoilDays_Fall_top50\nDrySoilDays_Winter_whole\nDrySoilDays_Spring_whole\nDrySoilDays_Summer_whole\nDrySoilDays_Fall_whole\nEvap_Winter\nEvap_Spring\nEvap_Summer\nEvap_Fall\nExtremeShortTermDryStress_Winter_top50\nExtremeShortTermDryStress_Spring_top50\nExtremeShortTermDryStress_Summer_top50\nExtremeShortTermDryStress_Fall_top50\nExtremeShortTermDryStress_Winter_whole\nExtremeShortTermDryStress_Spring_whole\nExtremeShortTermDryStress_Summer_whole\nExtremeShortTermDryStress_Fall_whole\nFrostDays_Winter\nFrostDays_Spring\nFrostDays_Summer\nFrostDays_Fall\nNonDrySWA_Winter_top50\nNonDrySWA_Spring_top50\nNonDrySWA_Summer_top50\nNonDrySWA_Fall_top50\nNonDrySWA_Winter_whole\nNonDrySWA_Spring_whole\nNonDrySWA_Summer_whole\nNonDrySWA_Fall_whole\nPET_Winter\nPET_Spring\nPET_Summer\nPET_Fall\nPPT_Winter\nPPT_Spring\nPPT_Summer\nPPT_Fall\nSemiDryDuration_Annual_top50\nSemiDryDuration_Annual_whole\nSWA_Winter_top50\nSWA_Spring_top50\nSWA_Summer_top50\nSWA_Fall_top50\nSWA_Winter_whole\nSWA_Spring_whole\nSWA_Summer_whole\nSWA_Fall_whole\nT_Winter\nT_Spring\nT_Summer\nT_Fall\nTmax_Winter\nTmax_Spring\nTmax_Summer\nTmax_Fall\nTmin_Winter\nTmin_Spring\nTmin_Summer\nTmin_Fall\nTransp_Winter\nTransp_Spring\nTransp_Summer\nTransp_Fall\nVWC_Winter_top50\nVWC_Spring_top50\nVWC_Summer_top50\nVWC_Fall_top50\nVWC_Winter_whole\nVWC_Spring_whole\nVWC_Summer_whole\nVWC_Fall_whole\nWetSoilDays_Winter_top50\nWetSoilDays_Spring_top50\nWetSoilDays_Summer_top50\nWetSoilDays_Fall_top50\nWetSoilDays_Winter_whole\nWetSoilDays_Spring_whole\nWetSoilDays_Summer_whole\nWetSoilDays_Fall_whole\nPPT_Annual\nT_Annual\n\n\n\n\n0\nNABR\n-110.0472\n37.60413\nShrubland\n1980\nHist\nhistorical\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n54.57202000\n1949.283\n-8753.784\n4834.13\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n13.79\n8.71\n2.69\n6.37\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n0.96483520\n8.767935\n23.15924\n11.962090\n14.15\n28.75\n37.05\n31.15\nNaN\nNaN\nNaN\nNaN\n0.2370806\n5.296833\n1.067496\n1.9667860\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n31.56\n11.21352505\n\n\n4\nNABR\n-110.0472\n37.60413\nShrubland\n1980\nHist\nhistorical\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n54.57202148\n1949.283\n-8753.784\n4834.13\n-0.6636760860\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n3.7140658366\n6.3995308949\n1.5598074021\n3.3632779979\nNaN\n24.34\n36.16\n29.52\nNaN\n24.34\n36.16\n29.52\n75.0\n34.0\n0.0\n26.0\n3.4668806371\n2.6546632530\n0.0321140671\n0.4880867481\n3.4668806371\n2.6546632530\n0.0321140671\n0.4880867481\n7.7811633032\n31.1394527955\n48.0177480655\n21.9156825756\nNaN\nNaN\nNaN\nNaN\n36.5000000000\n36.5000000000\n3.4668806371\n2.6546632530\n0.0321140671\n0.4880867481\n3.4668806371\n2.6546632530\n0.0321140671\n0.4880867481\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n-12.45\n-7.35\n5.55\n-10.25\nNaN\nNaN\nNaN\nNaN\n0.1134468701\n0.0968307001\n0.0418759016\n0.0522975530\n0.1134468701\n0.0968307001\n0.0418759016\n0.0522975530\n91.0\n77.0\n5.0\n47.0\n91.0\n77.0\n5.0\n47.0\nNaN\nNaN\n\n\n5\nNABR\n-110.0472\n37.60413\nShrubland\n1981\nHist\nhistorical\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n54.57202000\n1949.283\n-8753.784\n4834.13\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.25\n9.81\n9.39\n11.75\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n3.33444400\n10.548370\n23.27065\n11.581320\n17.05\n28.15\n37.55\n29.75\nNaN\nNaN\nNaN\nNaN\n0.2930753\n3.506108\n3.916328\n2.7875470\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n33.20\n12.18369600\n\n\n6\nNABR\n-110.0472\n37.60413\nShrubland\n1981\nHist\nhistorical\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n54.57202148\n1949.283\n-8753.784\n4834.13\n0.3478010620\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n2.1815202084\n5.9723378265\n5.0428776741\n4.6374034668\n13.92\n26.53\n36.08\nNaN\n13.92\n26.53\n36.08\nNaN\n79.0\n26.0\n0.0\n13.0\n0.3461917264\n0.8982752558\n0.0336629893\n2.5013360811\n0.3461917264\n0.8982752558\n0.0336629893\n2.5013360811\n8.1229049607\n32.3882557036\n48.1772426406\n21.7575735702\nNaN\nNaN\nNaN\nNaN\n13.2500000000\n13.2500000000\n0.3461917264\n0.8982752558\n0.0336629893\n2.5013360811\n0.3461917264\n0.8982752558\n0.0336629893\n2.5013360811\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n-9.35\n-5.55\n1.25\n-7.25\nNaN\nNaN\nNaN\nNaN\n0.0493818430\n0.0607271763\n0.0426386771\n0.0936706801\n0.0493818430\n0.0607271763\n0.0426386771\n0.0936706801\n48.0\n60.0\n13.0\n85.0\n48.0\n60.0\n13.0\n85.0\nNaN\nNaN\n\n\n7\nNABR\n-110.0472\n37.60413\nShrubland\n1982\nHist\nhistorical\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n54.57202000\n1949.283\n-8753.784\n4834.13\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n4.12\n5.10\n9.50\n9.83\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n-0.01555556\n9.472283\n22.05707\n9.869231\n14.35\n28.45\n36.65\n31.85\nNaN\nNaN\nNaN\nNaN\n0.2453347\n3.105047\n3.523923\n2.8900990\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n28.55\n10.34575711\n\n\n8\nNABR\n-110.0472\n37.60413\nShrubland\n1982\nHist\nhistorical\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n54.57202148\n1949.283\n-8753.784\n4834.13\n0.3260300992\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n3.2589947135\n4.7173273934\n4.5276363327\n4.2477717540\nNaN\n26.19\n34.99\n22.06\nNaN\n26.19\n34.99\n22.06\n83.0\n21.0\n0.0\n30.0\n3.2599844936\n1.5994982052\n0.1993822366\n1.2432253150\n3.2599844936\n1.5994982052\n0.1993822366\n1.2432253150\n7.3379526955\n31.4894498184\n47.1800768757\n21.0684231651\nNaN\nNaN\nNaN\nNaN\n17.2857142857\n17.2857142857\n3.2599844936\n1.5994982052\n0.1993822366\n1.2432253150\n3.2599844936\n1.5994982052\n0.1993822366\n1.2432253150\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n-16.55\n-7.25\n5.65\n-6.25\nNaN\nNaN\nNaN\nNaN\n0.1092341982\n0.0748166564\n0.0456102615\n0.0677891794\n0.1092341982\n0.0748166564\n0.0456102615\n0.0677891794\n90.0\n62.0\n19.0\n73.0\n90.0\n62.0\n19.0\n73.0\nNaN\nNaN\n\n\n9\nNABR\n-110.0472\n37.60413\nShrubland\n1983\nHist\nhistorical\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n54.57202000\n1949.283\n-8753.784\n4834.13\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n7.09\n10.80\n10.22\n10.40\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n0.40944440\n8.020652\n21.32826\n11.325820\n13.35\n30.65\n34.55\n33.15\nNaN\nNaN\nNaN\nNaN\n0.2252735\n4.962824\n5.006576\n1.1952350\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n38.51\n10.27104410\n\n\n10\nNABR\n-110.0472\n37.60413\nShrubland\n1983\nHist\nhistorical\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n54.57202148\n1949.283\n-8753.784\n4834.13\n0.0388273872\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n3.7419915365\n6.2671578978\n5.1695757094\n3.7751048188\nNaN\n28.56\n33.69\n31.02\nNaN\n28.56\n33.69\n31.02\n85.0\n32.0\n0.0\n19.0\n3.8064480379\n2.9456592119\n0.0960442305\n1.5835966242\n3.8064480379\n2.9456592119\n0.0960442305\n1.5835966242\n7.4798456947\n30.3128312703\n46.5762368398\n21.8471460016\nNaN\nNaN\nNaN\nNaN\n16.7142857143\n16.7142857143\n3.8064480379\n2.9456592119\n0.0960442305\n1.5835966242\n3.8064480379\n2.9456592119\n0.0960442305\n1.5835966242\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n-15.05\n-7.25\n3.85\n-8.95\nNaN\nNaN\nNaN\nNaN\n0.1204177901\n0.1025422325\n0.0441405046\n0.0748017843\n0.1204177901\n0.1025422325\n0.0441405046\n0.0748017843\n90.0\n74.0\n15.0\n69.0\n90.0\n74.0\n15.0\n69.0\nNaN\nNaN\n\n\n11\nNABR\n-110.0472\n37.60413\nShrubland\n1984\nHist\nhistorical\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n54.57202000\n1949.283\n-8753.784\n4834.13\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n4.77\n4.32\n9.49\n8.17\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n-1.04725300\n9.853804\n21.95978\n10.034070\n10.25\n32.75\n35.35\n31.35\nNaN\nNaN\nNaN\nNaN\n0.1226868\n3.120243\n4.269040\n0.9273169\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n26.75\n10.20010025\n\n\n15\nNABR\n-110.0472\n37.60413\nShrubland\n1984\nHist\nhistorical\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n54.57202148\n1949.283\n-8753.784\n4834.13\n0.2166602692\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n3.6272686835\n5.0078604793\n5.2303324404\n4.0803373430\nNaN\n30.95\n34.01\n29.52\nNaN\n30.95\n34.01\n29.52\n91.0\n35.0\n0.0\n30.0\n3.7945975224\n1.7555326024\n0.0452782946\n1.3792575946\n3.7945975224\n1.7555326024\n0.0452782946\n1.3792575946\n7.1730101555\n31.9972417196\n47.0386757592\n21.0183982059\nNaN\nNaN\nNaN\nNaN\n16.5000000000\n16.5000000000\n3.7945975224\n1.7555326024\n0.0452782946\n1.3792575946\n3.7945975224\n1.7555326024\n0.0452782946\n1.3792575946\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n-18.45\n-8.45\n2.95\n-12.45\nNaN\nNaN\nNaN\nNaN\n0.1202091711\n0.0778415354\n0.0431793330\n0.0703661709\n0.1202091711\n0.0778415354\n0.0431793330\n0.0703661709\n91.0\n65.0\n16.0\n62.0\n91.0\n65.0\n16.0\n62.0\nNaN\nNaN\n\n\n\n\n\n\n\n\n\nData Cleaning\na = test.drop('RL', axis=1)\nmerged_df = a.groupby(list(a.columns[0:21]), as_index=False).agg(lambda x: next(iter(x.dropna()), np.nan))\n\n\n\n\nData Cleaning\nrl = test.groupby(['veg','year','long','lat','scenario'])['RL'].mean().reset_index()\nmerged_df = pd.merge(merged_df, rl, on=['veg', 'year', 'long', 'lat', 'scenario'], how='inner')\n\n\n\n\nSanity Check\nprint(\"Original dataset rows with RL removed : \", merged_df.shape[0])\nprint(\"RL grouped and averaged by identifiers : \", rl.shape[0])\n\n\nOriginal dataset rows with RL removed :  361487\nRL grouped and averaged by identifiers :  361487\n\n\n\n\nCleaned Data\nmerged_df.head()\n\n\n\n\n\n\n\n\n\nPark\nlong\nlat\nveg\nyear\nTimePeriod\nRCP\nscenario\ntreecanopy\nAnn_Herb\nBare\nHerb\nLitter\nShrub\nEl\nSa\nCl\nRF\nSlope\nE\nS\nT_P_Corr\nDrySoilDays_Winter_top50\nDrySoilDays_Spring_top50\nDrySoilDays_Summer_top50\nDrySoilDays_Fall_top50\nDrySoilDays_Winter_whole\nDrySoilDays_Spring_whole\nDrySoilDays_Summer_whole\nDrySoilDays_Fall_whole\nEvap_Winter\nEvap_Spring\nEvap_Summer\nEvap_Fall\nExtremeShortTermDryStress_Winter_top50\nExtremeShortTermDryStress_Spring_top50\nExtremeShortTermDryStress_Summer_top50\nExtremeShortTermDryStress_Fall_top50\nExtremeShortTermDryStress_Winter_whole\nExtremeShortTermDryStress_Spring_whole\nExtremeShortTermDryStress_Summer_whole\nExtremeShortTermDryStress_Fall_whole\nFrostDays_Winter\nFrostDays_Spring\nFrostDays_Summer\nFrostDays_Fall\nNonDrySWA_Winter_top50\nNonDrySWA_Spring_top50\nNonDrySWA_Summer_top50\nNonDrySWA_Fall_top50\nNonDrySWA_Winter_whole\nNonDrySWA_Spring_whole\nNonDrySWA_Summer_whole\nNonDrySWA_Fall_whole\nPET_Winter\nPET_Spring\nPET_Summer\nPET_Fall\nPPT_Winter\nPPT_Spring\nPPT_Summer\nPPT_Fall\nSemiDryDuration_Annual_top50\nSemiDryDuration_Annual_whole\nSWA_Winter_top50\nSWA_Spring_top50\nSWA_Summer_top50\nSWA_Fall_top50\nSWA_Winter_whole\nSWA_Spring_whole\nSWA_Summer_whole\nSWA_Fall_whole\nT_Winter\nT_Spring\nT_Summer\nT_Fall\nTmax_Winter\nTmax_Spring\nTmax_Summer\nTmax_Fall\nTmin_Winter\nTmin_Spring\nTmin_Summer\nTmin_Fall\nTransp_Winter\nTransp_Spring\nTransp_Summer\nTransp_Fall\nVWC_Winter_top50\nVWC_Spring_top50\nVWC_Summer_top50\nVWC_Fall_top50\nVWC_Winter_whole\nVWC_Spring_whole\nVWC_Summer_whole\nVWC_Fall_whole\nWetSoilDays_Winter_top50\nWetSoilDays_Spring_top50\nWetSoilDays_Summer_top50\nWetSoilDays_Fall_top50\nWetSoilDays_Winter_whole\nWetSoilDays_Spring_whole\nWetSoilDays_Summer_whole\nWetSoilDays_Fall_whole\nPPT_Annual\nT_Annual\nRL\n\n\n\n\n0\nNABR\n-110.0472\n37.60413\nShrubland\n1980\nHist\nhistorical\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n1949.283\n-8753.784\n4834.13\n-0.6636760860\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n3.7140658366\n6.3995308949\n1.5598074021\n3.3632779979\nNaN\n24.34\n36.16\n29.52\nNaN\n24.34\n36.16\n29.52\n75.0\n34.0\n0.0\n26.0\n3.4668806371\n2.6546632530\n0.0321140671\n0.4880867481\n3.4668806371\n2.6546632530\n0.0321140671\n0.4880867481\n7.7811633032\n31.1394527955\n48.0177480655\n21.9156825756\n13.79\n8.71\n2.69\n6.37\n36.5000000000\n36.5000000000\n3.4668806371\n2.6546632530\n0.0321140671\n0.4880867481\n3.4668806371\n2.6546632530\n0.0321140671\n0.4880867481\n0.96483520\n8.767935\n23.15924\n11.962090\n14.15\n28.75\n37.05\n31.15\n-12.45\n-7.35\n5.55\n-10.25\n0.2370806\n5.296833\n1.067496\n1.9667860\n0.1134468701\n0.0968307001\n0.0418759016\n0.0522975530\n0.1134468701\n0.0968307001\n0.0418759016\n0.0522975530\n91.0\n77.0\n5.0\n47.0\n91.0\n77.0\n5.0\n47.0\n31.56\n11.21352505\n54.57202074\n\n\n1\nNABR\n-110.0472\n37.60413\nShrubland\n1981\nHist\nhistorical\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n1949.283\n-8753.784\n4834.13\n0.3478010620\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n2.1815202084\n5.9723378265\n5.0428776741\n4.6374034668\n13.92\n26.53\n36.08\nNaN\n13.92\n26.53\n36.08\nNaN\n79.0\n26.0\n0.0\n13.0\n0.3461917264\n0.8982752558\n0.0336629893\n2.5013360811\n0.3461917264\n0.8982752558\n0.0336629893\n2.5013360811\n8.1229049607\n32.3882557036\n48.1772426406\n21.7575735702\n2.25\n9.81\n9.39\n11.75\n13.2500000000\n13.2500000000\n0.3461917264\n0.8982752558\n0.0336629893\n2.5013360811\n0.3461917264\n0.8982752558\n0.0336629893\n2.5013360811\n3.33444400\n10.548370\n23.27065\n11.581320\n17.05\n28.15\n37.55\n29.75\n-9.35\n-5.55\n1.25\n-7.25\n0.2930753\n3.506108\n3.916328\n2.7875470\n0.0493818430\n0.0607271763\n0.0426386771\n0.0936706801\n0.0493818430\n0.0607271763\n0.0426386771\n0.0936706801\n48.0\n60.0\n13.0\n85.0\n48.0\n60.0\n13.0\n85.0\n33.20\n12.18369600\n54.57202074\n\n\n2\nNABR\n-110.0472\n37.60413\nShrubland\n1982\nHist\nhistorical\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n1949.283\n-8753.784\n4834.13\n0.3260300992\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n3.2589947135\n4.7173273934\n4.5276363327\n4.2477717540\nNaN\n26.19\n34.99\n22.06\nNaN\n26.19\n34.99\n22.06\n83.0\n21.0\n0.0\n30.0\n3.2599844936\n1.5994982052\n0.1993822366\n1.2432253150\n3.2599844936\n1.5994982052\n0.1993822366\n1.2432253150\n7.3379526955\n31.4894498184\n47.1800768757\n21.0684231651\n4.12\n5.10\n9.50\n9.83\n17.2857142857\n17.2857142857\n3.2599844936\n1.5994982052\n0.1993822366\n1.2432253150\n3.2599844936\n1.5994982052\n0.1993822366\n1.2432253150\n-0.01555556\n9.472283\n22.05707\n9.869231\n14.35\n28.45\n36.65\n31.85\n-16.55\n-7.25\n5.65\n-6.25\n0.2453347\n3.105047\n3.523923\n2.8900990\n0.1092341982\n0.0748166564\n0.0456102615\n0.0677891794\n0.1092341982\n0.0748166564\n0.0456102615\n0.0677891794\n90.0\n62.0\n19.0\n73.0\n90.0\n62.0\n19.0\n73.0\n28.55\n10.34575711\n54.57202074\n\n\n3\nNABR\n-110.0472\n37.60413\nShrubland\n1983\nHist\nhistorical\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n1949.283\n-8753.784\n4834.13\n0.0388273872\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n3.7419915365\n6.2671578978\n5.1695757094\n3.7751048188\nNaN\n28.56\n33.69\n31.02\nNaN\n28.56\n33.69\n31.02\n85.0\n32.0\n0.0\n19.0\n3.8064480379\n2.9456592119\n0.0960442305\n1.5835966242\n3.8064480379\n2.9456592119\n0.0960442305\n1.5835966242\n7.4798456947\n30.3128312703\n46.5762368398\n21.8471460016\n7.09\n10.80\n10.22\n10.40\n16.7142857143\n16.7142857143\n3.8064480379\n2.9456592119\n0.0960442305\n1.5835966242\n3.8064480379\n2.9456592119\n0.0960442305\n1.5835966242\n0.40944440\n8.020652\n21.32826\n11.325820\n13.35\n30.65\n34.55\n33.15\n-15.05\n-7.25\n3.85\n-8.95\n0.2252735\n4.962824\n5.006576\n1.1952350\n0.1204177901\n0.1025422325\n0.0441405046\n0.0748017843\n0.1204177901\n0.1025422325\n0.0441405046\n0.0748017843\n90.0\n74.0\n15.0\n69.0\n90.0\n74.0\n15.0\n69.0\n38.51\n10.27104410\n54.57202074\n\n\n4\nNABR\n-110.0472\n37.60413\nShrubland\n1984\nHist\nhistorical\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n1949.283\n-8753.784\n4834.13\n0.2166602692\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n3.6272686835\n5.0078604793\n5.2303324404\n4.0803373430\nNaN\n30.95\n34.01\n29.52\nNaN\n30.95\n34.01\n29.52\n91.0\n35.0\n0.0\n30.0\n3.7945975224\n1.7555326024\n0.0452782946\n1.3792575946\n3.7945975224\n1.7555326024\n0.0452782946\n1.3792575946\n7.1730101555\n31.9972417196\n47.0386757592\n21.0183982059\n4.77\n4.32\n9.49\n8.17\n16.5000000000\n16.5000000000\n3.7945975224\n1.7555326024\n0.0452782946\n1.3792575946\n3.7945975224\n1.7555326024\n0.0452782946\n1.3792575946\n-1.04725300\n9.853804\n21.95978\n10.034070\n10.25\n32.75\n35.35\n31.35\n-18.45\n-8.45\n2.95\n-12.45\n0.1226868\n3.120243\n4.269040\n0.9273169\n0.1202091711\n0.0778415354\n0.0431793330\n0.0703661709\n0.1202091711\n0.0778415354\n0.0431793330\n0.0703661709\n91.0\n65.0\n16.0\n62.0\n91.0\n65.0\n16.0\n62.0\n26.75\n10.20010025\n54.57202074\n\n\n\n\n\n\n\n\n\nOutput to CSV\n# merged_df.to_csv('../data/cleaned_df.csv', index=False)"
  },
  {
    "objectID": "Analysis.html",
    "href": "Analysis.html",
    "title": "Dataset Analysis",
    "section": "",
    "text": "As mentioned in the EDA tab, we will drill down into the dataset with two main depths RCP and scenario. For each RCP value (4.5, 8.5), I will conduct the following four types of analysis to compare and contrast important variables that separate the scenarios and effect the annual temperature\nMethodology\n\nScatterplot\nPCA\nPearson Correlation\nRMSE\n\n\n\nImport module / Set options and theme\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport xml.etree.ElementTree as ET\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom scipy.stats import ttest_rel\nfrom statsmodels.stats.weightstats import ttest_ind\nimport numpy as np\nimport pingouin as pg\nfrom scipy.stats import zscore\nimport plotly.graph_objects as go\nimport pandas as pd\nfrom plotly.subplots import make_subplots\nimport warnings\nimport numpy as np\nimport pandas as pd\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nimport numpy as np\nimport pandas as pd\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nimport plotly.express as px\nfrom sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nwarnings.filterwarnings(\"ignore\")\n\npd.set_option('display.max_columns', None)\npd.set_option('display.precision', 10)\n\n\n\n\nImport cleaned data\ndf = pd.read_csv('../data/cleaned_df.csv')\ndf['Location_ID'] = df.groupby(['long', 'lat']).ngroup() + 1\n\ngroup_list = ['Park', 'long', 'lat', 'veg', 'year', 'TimePeriod', 'RCP','treecanopy', 'Ann_Herb', 'Bare', 'Herb', 'Litter', 'Shrub', 'El', 'Sa','Cl', 'RF', 'Slope', 'E', 'S']\nveg_location = df.drop(labels='scenario',axis=1).groupby(group_list).mean().reset_index()\n# veg_location['T_Annual'] = (veg_location['T_Annual'] - veg_location['T_Annual'].min()) / (veg_location['T_Annual'].max() - veg_location['T_Annual'].min())\n\n\n# Average Scenario Dataset\n# Convert to numeric, coercing errors to NaN\nnumeric_series = pd.to_numeric(veg_location['RCP'], errors='coerce')\n\nnumeric_series\n\n# Fill NaNs with original non-numeric values\nveg_location['RCP'] = numeric_series.fillna(veg_location['RCP'])\n\nfour = veg_location[veg_location['RCP'].isin([4.5])]\neight = veg_location[veg_location['RCP'].isin([8.5])]\nfour_h = veg_location[veg_location['RCP'].isin(['historical'])]\nfour_h['RCP'] = 4.5\neight_h = veg_location[veg_location['RCP'].isin(['historical'])]\neight_h['RCP'] = 8.5\n\ndf_con = pd.concat([four_h, four, eight_h, eight], ignore_index=True)\ndf_con['Location_ID'] = df_con.groupby(['long', 'lat']).ngroup() + 1\n\n\n# Scenario Dataset\n# Convert to numeric, coercing errors to NaN\nnumeric_series = pd.to_numeric(df['RCP'], errors='coerce')\n\nnumeric_series\n\n# Fill NaNs with original non-numeric values\ndf['RCP'] = numeric_series.fillna(df['RCP'])\n\nfour = df[df['RCP'].isin([4.5])]\neight = df[df['RCP'].isin([8.5])]\nfour_h = df[df['RCP'].isin(['historical'])]\nfour_h['RCP'] = 4.5\neight_h = df[df['RCP'].isin(['historical'])]\neight_h['RCP'] = 8.5\n\ndf_orig = pd.concat([four_h, four, eight_h, eight], ignore_index=True)\ndf_orig['Location_ID'] = df_orig.groupby(['long', 'lat']).ngroup() + 1"
  },
  {
    "objectID": "Analysis.html#scatterplot",
    "href": "Analysis.html#scatterplot",
    "title": "Dataset Analysis",
    "section": "Scatterplot",
    "text": "Scatterplot\nWith a basic scatterplot, we can see basic correlations of how each numerical variable correlates to either the annual temperature or the annual percipitation. Since RCP 8.5 and RCP 4.5 have different predictions, two plots were used for each scenario.\nFirstly, without an additional feature, we can see that the more percipitation, the lower the annual temperature because we can easily draw a line with a negative slope through the scaterred plots.\n\n\n4.5 vs 8.5 scatterplot\n# Assuming df_con is your DataFrame and is already loaded\n# List of columns to use for coloring\ntest = df_con.iloc[:,list(range(1, 3))+ [4,6] + list(range(8, len(df_orig.columns)-1))]\ncolor_columns = list(test.columns)\nrcp_values = test['RCP'].unique()\n\nsubplot_titles = [f'RCP {rcp}' for rcp in rcp_values]\n\n# Create figure with subplots for each RCP value\nfig = make_subplots(rows=1, cols=len(rcp_values), shared_yaxes=True, subplot_titles=subplot_titles, horizontal_spacing=0.15)\n\n# Add a scatter trace for each color column and each RCP value\nfor i, col in enumerate(color_columns):\n    for j, rcp in enumerate(rcp_values):\n        fig.add_trace(\n            go.Scatter(\n                x=test[(test['year'].isin(range(2060, 2100))) & (test['RCP'] == rcp)]['PPT_Annual'],\n                y=test[(test['year'].isin(range(2060, 2100))) & (test['RCP'] == rcp)]['T_Annual'],\n                mode='markers',\n                marker=dict(\n                    color=test[(test['year'].isin(range(2060, 2100))) & (test['RCP'] == rcp)][col],\n                    colorbar=dict(\n                        # title='Scale',\n                                  tickmode='array',\n                                  tickvals=[round(i,2) for i in np.linspace(start=round(min(test[(test['year'].isin(range(2060, 2100)) & (test['RCP'] == rcp))][col]),2),stop=round(max(test[(test['year'].isin(range(2060, 2100)) & (test['RCP'] == rcp))][col]),2),num=5)],\n                                  ticktext=[round(i,2) for i in np.linspace(start=round(min(test[(test['year'].isin(range(2060, 2100)) & (test['RCP'] == rcp))][col]),2),stop=round(max(test[(test['year'].isin(range(2060, 2100)) & (test['RCP'] == rcp))][col]),2),num=5)],\n                                  y=0.5,\n                                  x= 0.43 + (j*0.58)\n                                  ),\n                                  colorscale='rdpu'\n                ),\n                name=col,\n                visible=True if i == 0 else False,\n                hovertemplate=(\n                    f\"&lt;b&gt;{col}&lt;/b&gt;&lt;br&gt;\"\n                    \"Precipitation: %{x}&lt;br&gt;\"\n                    \"Temperature: %{y}&lt;br&gt;\"\n                    \"RCP: \" + str(rcp) + \"&lt;br&gt;\"\n                    \"Value: %{marker.color}&lt;br&gt;\"\n                    \"&lt;extra&gt;&lt;/extra&gt;\"\n                  )  # This hides the secondary box with trace info  # Only the first trace is visible initially\n            ),\n            row=1, col=j+1\n        )\n\n# Updating the layout to add the title\nfig.update_layout(\n    title={\n        'text': '&lt;b&gt;Annual Precipitation vs Temperature by RCP Scenarios&lt;/b&gt;',\n        'x': 0.5,\n        'y': 0.97,\n        'xanchor': 'center'\n    },\n    # title_font=dict(size=20),\n    showlegend=False  # Hide legend since we are using colorbars\n)\n\n# Adding dropdown filter to change visible trace\ndropdown_buttons = [\n    {\n        'label': col,\n        'method': 'update',\n        'args': [\n            {\n                'visible': [col == color_column for color_column in color_columns for _ in rcp_values]\n            },\n            {\n                'title': {'text': f'&lt;b&gt;Annual Precipitation vs Temperature by {col}&lt;/b&gt;', 'x':0.5, 'y':0.97},\n                'marker': {'colorbar': {'title': 'Scale'}}\n            }\n        ]\n    }\n    for col in color_columns\n]\n\nfig.update_layout(\n    updatemenus=[\n        {\n            'buttons': dropdown_buttons,\n            'direction': 'down',\n            'showactive': True,\n            'x': 0.5,\n            'xanchor': 'center',\n            'y': 1.19,\n            'yanchor': 'top'\n        }\n    ]\n)\n\nfig.update_xaxes(title_text=\"Annual Precipitation\", row=1, col=1)\nfig.update_yaxes(title_text=\"Annual Temperature\", row=1, col=1)\nfig.update_xaxes(title_text=\"Annual Precipitation\", row=1, col=2)\n\nfor annotation in fig['layout']['annotations']:\n    annotation['font'] = {'size': 12, 'color': 'black'}\n\n# Show the figure\nfig.show()\n\n\n\n                                                \n\n\n\nUseful Variables\nBy trying each numerical variable as a color metric for the scatter plots, four important features that I found are as below:\n\nVWC_Summer_whole\nWetSoilDays_Spring_whole\nSWA_Fall_whole\nBare\n\nFor now, rather than focusing on the seasonality of the variables, lets focus on VWC, WetSoilDays, SWA and Bare. We can infer that it is important to keep the land moist to a certain level and minimize the ‘bareness’ in the area to lower the temperature. Lets move on to each RCP scenario for a more detailed analysis.\n\n\nImportant Features\nfeature = 'VWC_Summer_whole'\nfig = px.scatter(df_con[df_con['year'].isin(range(2060,2099))], x=\"PPT_Annual\", y=\"T_Annual\",\n                 color=feature, facet_col=\"RCP\",     \n                 labels={\n        feature: 'Scale'  # Replace with your desired colorbar title\n    })\nfig.update_layout(\n    title={\n        'text': f'&lt;b&gt;Annual Precipitation/Temperature ({feature})&lt;/b&gt;',\n        # 'y':0.95,  # This adjusts the position of the title (vertically)\n        'x':0.5,   # Centers the title horizontally\n        'xanchor': 'center',  # Ensures the title is centered at the specified x position\n        # 'yanchor': 'top'  # Ensures the title is positioned based on the top of the text\n    },\n    title_font=dict(size=20)  # Custom font settings\n)\nfig.show()\n\n\nfeature = 'WetSoilDays_Spring_whole'\nfig = px.scatter(df_con[df_con['year'].isin(range(2060,2099))], x=\"PPT_Annual\", y=\"T_Annual\",\n                 color=feature, facet_col=\"RCP\",     \n                 labels={\n        feature: 'Scale'  # Replace with your desired colorbar title\n    })\nfig.update_layout(\n    title={\n        'text': f'&lt;b&gt;Annual Precipitation/Temperature ({feature})&lt;/b&gt;',\n        # 'y':0.95,  # This adjusts the position of the title (vertically)\n        'x':0.5,   # Centers the title horizontally\n        'xanchor': 'center',  # Ensures the title is centered at the specified x position\n        # 'yanchor': 'top'  # Ensures the title is positioned based on the top of the text\n    },\n    title_font=dict(size=20)  # Custom font settings\n)\n\nfig.show()\n\nfeature = 'SWA_Fall_whole'\nfig = px.scatter(df_con[df_con['year'].isin(range(2060,2099))], x=\"PPT_Annual\", y=\"T_Annual\",\n                 color=feature, facet_col=\"RCP\",     \n                 labels={\n        feature: 'Scale'  # Replace with your desired colorbar title\n    })\nfig.update_layout(\n    title={\n        'text': f'&lt;b&gt;Annual Precipitation/Temperature ({feature})&lt;/b&gt;',\n        # 'y':0.95,  # This adjusts the position of the title (vertically)\n        'x':0.5,   # Centers the title horizontally\n        'xanchor': 'center',  # Ensures the title is centered at the specified x position\n        # 'yanchor': 'top'  # Ensures the title is positioned based on the top of the text\n    },\n    title_font=dict(size=20)  # Custom font settings\n)\n\nfig.show()"
  },
  {
    "objectID": "Analysis.html#pearson-correlation",
    "href": "Analysis.html#pearson-correlation",
    "title": "Dataset Analysis",
    "section": "Pearson Correlation",
    "text": "Pearson Correlation\n\nRCP4.5\nBy calculating a Pearson correlation matrix for all numerical variables in the dataset, we can create a heatmap to explore the relationships between different features. This visualization helps identify which features affect each other and highlights those that correlate most strongly with the annual temperature.\nIn the second plot below, we see that the highest correlators are:\n\nSeasonal temperature\nFrost days\n\nWhile these factors cannot be directly influenced, we can take action on the following to mitigate their effects:\n\nExtreme short-term dry stress\nPET (Potential Evapotranspiration)\nSWA (Soil Water Availability)\nVWC (Volumetric Water Content)\n\n\n\nCorrelation Heatmap\n# Calculate the correlation matrix\ncorr_matrix = df_orig[(df_orig['TimePeriod']!='Hist') & (df_orig['RCP']==4.5)].iloc[:,8:].corr()\n\n\n# Create an interactive heatmap of the correlation matrix\nfig = px.imshow(corr_matrix,\n                # text_auto=True,  # Automatically add text in each cell\n                labels=dict(color=\"Correlation\"),\n                x=corr_matrix.columns,\n                y=corr_matrix.columns,\n                color_continuous_scale='RdBu_r'\n  )  # Red-Blue color map, reversed\n\nfig.update_layout(\n    width=800,  # Width of the figure in pixels\n    height=900,  # Height of the figure in pixels\n    margin=dict(l=10, r=1, t=50, b=10)  # Reducing margins around the plot\n)\n\n# Adjusting color bar position\n# fig.update_layout(coloraxis_colorbar=dict(\n#     x=0.8  # Adjusts the horizontal position of the color bar\n# ))\nfig.update_layout(title_text='&lt;b&gt;Future Correlation Heatmap : RCP 4.5&lt;/b&gt;',  # Bold text using HTML\n                  title_x=0.5)  # Centers the title by setting the x position to 0.5\n\nfig.update_xaxes(tickfont=dict(size=10))  # Sets the font size of x-axis labels\nfig.update_yaxes(tickfont=dict(size=10))  # Sets the font size of y-axis labels\n# fig.update_xaxes(side=\"bottom\")\nfig.show()\n\n\n\n                                                \n\n\n\n\nCorrelation Feature Importance\n# Sort the features by the absolute value of the loading for PCA1\nsorted_loadings = corr_matrix['T_Annual'].abs().sort_values(ascending=False)\n\n# Get the top 10 most influential features\ntop_features = sorted_loadings.head(40).index\n\n# Get the actual loadings for these top 10 features\ntop_loadings = round(corr_matrix['T_Annual'].loc[top_features,],4)[1:]\n\n# Create a color list based on the sign of the loadings\ncolors = ['blue' if val &gt; 0 else 'red' for val in top_loadings]\n\n# Create a bar chart\nfig = go.Figure(data=[go.Bar(\n    x=top_loadings.index,\n    y=top_loadings.abs(),\n    text=top_loadings.values,  # Show the actual values as text\n    textposition='inside',\n    marker_color=colors,\n    showlegend=False\n)])\n\n# Add legend manually\nfig.add_trace(go.Bar(\n    x=[None], y=[None],\n    marker=dict(color='blue'),\n    showlegend=True,\n    name='Positive'\n))\nfig.add_trace(go.Bar(\n    x=[None], y=[None],\n    marker=dict(color='red'),\n    showlegend=True,\n    name='Negative'\n))\n\n# Update layout for better readability\nfig.update_layout(\n    title='&lt;b&gt;Top Features Correlating to Annual Temperature (RCP = 4.5)/b&gt;',\n    xaxis_title='Features',\n    yaxis_title='Absolute PCA1 Loadings',\n    yaxis=dict(tickformat=\".2f\"),\n    xaxis=dict(\n        tickangle=45,  # Rotate x ticks\n        tickfont=dict(size=10)  # Make the font smaller\n    ),\n    template='plotly_white',\n    legend=dict(\n        orientation=\"h\",\n        yanchor=\"bottom\",\n        y=1.02,\n        xanchor=\"right\",\n        x=1\n    ),\n    margin=dict(l=20, r=20, b=20, t=60)\n)\n\nfig.show()\n\n\n\n                                                \n\n\n\n\nRCP8.5\nIn the analysis of Pearson correlation for different RCP (Representative Concentration Pathway) scenarios, it was observed that the ranking of features changed between the RCP 4.5 and RCP 8.5 scenarios. Here’s a detailed comparison:\n\nSimilarities:\n\nTop-Ranked Features: In both scenarios, seasonal temperatures were the highest-ranked features.\nExtreme Short-Term Dry Stress: This feature followed closely behind seasonal temperatures in both scenarios.\nFrost Days: Features related to frost days also appeared prominently in the middle of the rankings for both scenarios.\n\n\n\nDifferences:\n\nRCP 4.5 Scenario:\n\nVWC (Volumetric Water Content) and SWA (Soil Water Availability): These variables appeared towards the 30th to 40th rankings of correlations. This indicates a moderate influence of water-related variables under the RCP 4.5 scenario.\n\nRCP 8.5 Scenario:\n\nTemperature-Related Variables: There was a noticeable increase in the number of temperature-related variables such as Tmin (minimum temperature) and Tmax (maximum temperature).\nDecrease in VWC and SWA Features: The number of VWC and SWA features significantly decreased, and their places in the ranking were taken over by temperature-related variables.\n\n\n\n\nImplications:\n\nRCP 4.5: This scenario suggests a balanced influence of both temperature and water-related variables.\nRCP 8.5: Under this more extreme scenario, temperature variables become more dominant, overshadowing the influence of water-related variables.\n\nThese differences highlight how the impact of climate variables can shift under different greenhouse gas concentration pathways, with temperature effects becoming more pronounced under higher emission scenarios.\nWhat does this mean? With the knowledge that 8.5 means higher CO2 emission as mentioned in the EDA tab, we can imply that if the RCP8.5 scenario takes place, there is less room for people to prevent temperatures from rising and preserving the environment. This is a logical statement even without the data but the data reinforces the idea by showing less variables in the pearson correlation with the annual temperature.\n\n\nCorrelation Heatmap\n# Calculate the correlation matrix\ncorr_matrix = df_orig[(df_orig['TimePeriod']!='Hist') & (df_orig['RCP']==8.5)].iloc[:,8:].corr()\n\n\n# Create an interactive heatmap of the correlation matrix\nfig = px.imshow(corr_matrix,\n                # text_auto=True,  # Automatically add text in each cell\n                labels=dict(color=\"Correlation\"),\n                x=corr_matrix.columns,\n                y=corr_matrix.columns,\n                color_continuous_scale='RdBu_r'\n  )  # Red-Blue color map, reversed\n\nfig.update_layout(\n    width=800,  # Width of the figure in pixels\n    height=900,  # Height of the figure in pixels\n    margin=dict(l=10, r=1, t=50, b=10)  # Reducing margins around the plot\n)\n\n# Adjusting color bar position\n# fig.update_layout(coloraxis_colorbar=dict(\n#     x=0.8  # Adjusts the horizontal position of the color bar\n# ))\nfig.update_layout(title_text='&lt;b&gt;Future Correlation Heatmap : RCP 8.5&lt;/b&gt;',  # Bold text using HTML\n                  title_x=0.5)  # Centers the title by setting the x position to 0.5\n\nfig.update_xaxes(tickfont=dict(size=10))  # Sets the font size of x-axis labels\nfig.update_yaxes(tickfont=dict(size=10))  # Sets the font size of y-axis labels\n# fig.update_xaxes(side=\"bottom\")\nfig.show()\n\n\n\n                                                \n\n\n\n\nCorrelation Feature Importance\n# Sort the features by the absolute value of the loading for PCA1\nsorted_loadings = corr_matrix['T_Annual'].abs().sort_values(ascending=False)\n\n# Get the top 10 most influential features\ntop_features = sorted_loadings.head(30).index\n\n# Get the actual loadings for these top 10 features\ntop_loadings = round(corr_matrix['T_Annual'].loc[top_features,],4)[1:]\n\n# Create a color list based on the sign of the loadings\ncolors = ['blue' if val &gt; 0 else 'red' for val in top_loadings]\n\n# Create a bar chart\nfig = go.Figure(data=[go.Bar(\n    x=top_loadings.index,\n    y=top_loadings.abs(),\n    text=top_loadings.values,  # Show the actual values as text\n    textposition='inside',\n    marker_color=colors,\n    showlegend=False\n)])\n\n# Add legend manually\nfig.add_trace(go.Bar(\n    x=[None], y=[None],\n    marker=dict(color='blue'),\n    showlegend=True,\n    name='Positive'\n))\nfig.add_trace(go.Bar(\n    x=[None], y=[None],\n    marker=dict(color='red'),\n    showlegend=True,\n    name='Negative'\n))\n\n# Update layout for better readability\nfig.update_layout(\n    title='&lt;b&gt;Top Features Correlating to Annual Temperature&lt;/b&gt;',\n    xaxis_title='Features',\n    yaxis_title='Absolute PCA1 Loadings',\n    yaxis=dict(tickformat=\".2f\"),\n    xaxis=dict(\n        tickangle=45,  # Rotate x ticks\n        tickfont=dict(size=10)  # Make the font smaller\n    ),\n    template='plotly_white',\n    legend=dict(\n        orientation=\"h\",\n        yanchor=\"bottom\",\n        y=1.02,\n        xanchor=\"right\",\n        x=1\n    ),\n    margin=dict(l=20, r=20, b=20, t=60)\n)\n\nfig.show()"
  },
  {
    "objectID": "Analysis.html#pca",
    "href": "Analysis.html#pca",
    "title": "Dataset Analysis",
    "section": "PCA",
    "text": "PCA\nWhat is PCA? Principal Component Analysis (PCA) is a statistical technique used to reduce the dimensionality of a dataset while preserving as much variance as possible. It transforms the original variables into a new set of uncorrelated variables called principal components, which are ordered by the amount of variance they capture from the data. The first principal component captures the most variance, followed by the second, and so on. PCA is widely used in data analysis and machine learning for feature reduction, noise reduction, and visualization of high-dimensional data. By simplifying the dataset, PCA can help improve the performance of algorithms and make data more interpretable.\nWhat will we do with this? We will conduct PCA on each group of RCP to find a pattern in between scenarios and how they group within the reduced dimensionality. Based on how they are grouped and how much each column feature influenced the principal component, we will be able to estimate what features diferentiated different scenarios.\n\n\nPCA(RCP = 4.5)\ndata = df_orig[(df_orig['RCP']==4.5) & (df_orig['year'].isin(range(2095,2100)))].dropna(axis=1, how='any')\nX = data.iloc[:,list(range(1, 3))+ [4,6] + list(range(8, len(data.columns)-3))]\n\n# Standardize the features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Apply PCA\npca = PCA(n_components=10)  # Reduce to 2 components for visualization\nX_pca = pca.fit_transform(X_scaled)\n\n# Add the PCA and cluster results to the DataFrame\ndata['PCA1'] = X_pca[:, 0]\ndata['PCA2'] = X_pca[:, 1]\ndata['PCA3'] = X_pca[:, 2]\n\n# Get the component loadings\nloadings = pca.components_.T\ncolumns = X.columns\n\n# Create a DataFrame for loadings\nloadings_df = pd.DataFrame(loadings, columns=['PCA1', 'PCA2', 'PCA3', 'PCA4', 'PCA5', 'PCA6', 'PCA7', 'PCA8', 'PCA9', 'PCA10'], index=columns)\n\n# Get the explained variance ratio\nexplained_variance_ratio = pca.explained_variance_ratio_\n\n# Cumulative explained variance\ncumulative_explained_variance = np.cumsum(explained_variance_ratio)\n\n\n\nExplained Variance\nBy using the elbow method, we can guess that we need principal components 1, 2, and maybe 3. Lets plot the points out along with\n\n\nVarience Ratio\n# Create a list of x-axis labels from PCA1 to PCA10\nx_labels = [f'PCA{i+1}' for i in range(len(explained_variance_ratio))]\n\n# Create a line chart for explained variance ratio\nfig = go.Figure(data=go.Scatter(\n    x=x_labels,\n    y=explained_variance_ratio,\n    mode='lines+markers',\n    text=explained_variance_ratio,\n    textposition='top center'\n))\n\n# Update layout for better readability\nfig.update_layout(\n    title='&lt;b&gt;Explained Variance Ratio by Principal Components&lt;/b&gt;',\n    xaxis_title='Principal Components',\n    yaxis_title='Explained Variance Ratio',\n    yaxis=dict(tickformat=\".2%\", range=[0, 1.1 * explained_variance_ratio.max()]),  # Adjust the range as needed\n    template='plotly_white',\n    margin=dict(l=50, r=50, b=50, t=50)  # Adjust the padding as needed\n)\n\nfig.show()\n\n\n\n                                                \n\n\n\n\nPCA feature importance\nIn order to interpret visualizations made from principle components, we need to understand what features effect each component. The following bar graphs are features that influence each component the most ranked by their absolute value and the direction(Positive, Negative) differentiated by color.\n\n\nFeature Importance Plots\n# Sort the features by the absolute value of the loading for PCA1\nsorted_loadings = loadings_df['PCA1'].abs().sort_values(ascending=False)\n\n# Get the top 10 most influential features\ntop_features = sorted_loadings.head(30).index\n\n# Get the actual loadings for these top 10 features\ntop_loadings = round(loadings_df.loc[top_features, 'PCA1'],4)\n\n# Create a color list based on the sign of the loadings\ncolors = ['blue' if val &gt; 0 else 'red' for val in top_loadings]\n\n# Create a bar chart\nfig = go.Figure(data=[go.Bar(\n    x=top_loadings.index,\n    y=top_loadings.abs(),\n    text=top_loadings.values,  # Show the actual values as text\n    textposition='inside',\n    marker_color=colors,\n    showlegend=False\n)])\n\n# Add legend manually\nfig.add_trace(go.Bar(\n    x=[None], y=[None],\n    marker=dict(color='blue'),\n    showlegend=True,\n    name='Positive'\n))\nfig.add_trace(go.Bar(\n    x=[None], y=[None],\n    marker=dict(color='red'),\n    showlegend=True,\n    name='Negative'\n))\n\n# Update layout for better readability\nfig.update_layout(\n    title='&lt;b&gt;Top 20 Most Influential Features on PCA1&lt;/b&gt;',\n    xaxis_title='Features',\n    yaxis_title='Absolute PCA1 Loadings',\n    yaxis=dict(tickformat=\".2f\"),\n    template='plotly_white',\n    legend=dict(\n        orientation=\"h\",\n        yanchor=\"bottom\",\n        y=1.02,\n        xanchor=\"right\",\n        x=1\n    ),\n    margin=dict(l=20, r=20, b=20, t=60)\n)\n\nfig.show()\n\n# Sort the features by the absolute value of the loading for PCA1\nsorted_loadings = loadings_df['PCA2'].abs().sort_values(ascending=False)\n\n# Get the top 10 most influential features\ntop_features = sorted_loadings.head(30).index\n\n# Get the actual loadings for these top 10 features\ntop_loadings = round(loadings_df.loc[top_features, 'PCA2'],4)\n\n# Create a color list based on the sign of the loadings\ncolors = ['blue' if val &gt; 0 else 'red' for val in top_loadings]\n\n# Create a bar chart\nfig = go.Figure(data=[go.Bar(\n    x=top_loadings.index,\n    y=top_loadings.abs(),\n    text=top_loadings.values,  # Show the actual values as text\n    textposition='inside',\n    marker_color=colors,\n    showlegend=False\n)])\n\n# Add legend manually\nfig.add_trace(go.Bar(\n    x=[None], y=[None],\n    marker=dict(color='blue'),\n    showlegend=True,\n    name='Positive'\n))\nfig.add_trace(go.Bar(\n    x=[None], y=[None],\n    marker=dict(color='red'),\n    showlegend=True,\n    name='Negative'\n))\n\n# Update layout for better readability\nfig.update_layout(\n    title='&lt;b&gt;Top 20 Most Influential Features on PCA2&lt;/b&gt;',\n    xaxis_title='Features',\n    yaxis_title='Absolute PCA1 Loadings',\n    yaxis=dict(tickformat=\".2f\"),\n    template='plotly_white',\n    legend=dict(\n        orientation=\"h\",\n        yanchor=\"bottom\",\n        y=1.02,\n        xanchor=\"right\",\n        x=1\n    ),\n    margin=dict(l=20, r=20, b=20, t=60)\n)\n\nfig.show()\n\n# Sort the features by the absolute value of the loading for PCA1\nsorted_loadings = loadings_df['PCA3'].abs().sort_values(ascending=False)\n\n# Get the top 10 most influential features\ntop_features = sorted_loadings.head(30).index\n\n# Get the actual loadings for these top 10 features\ntop_loadings = round(loadings_df.loc[top_features, 'PCA3'],4)\n\n# Create a color list based on the sign of the loadings\ncolors = ['blue' if val &gt; 0 else 'red' for val in top_loadings]\n\n# Create a bar chart\nfig = go.Figure(data=[go.Bar(\n    x=top_loadings.index,\n    y=top_loadings.abs(),\n    text=top_loadings.values,  # Show the actual values as text\n    textposition='inside',\n    marker_color=colors,\n    showlegend=False\n)])\n\n# Add legend manually\nfig.add_trace(go.Bar(\n    x=[None], y=[None],\n    marker=dict(color='blue'),\n    showlegend=True,\n    name='Positive'\n))\nfig.add_trace(go.Bar(\n    x=[None], y=[None],\n    marker=dict(color='red'),\n    showlegend=True,\n    name='Negative'\n))\n\n# Update layout for better readability\nfig.update_layout(\n    title='&lt;b&gt;Top 20 Most Influential Features on PCA3&lt;/b&gt;',\n    xaxis_title='Features',\n    yaxis_title='Absolute PCA1 Loadings',\n    yaxis=dict(tickformat=\".2f\"),\n    template='plotly_white',\n    legend=dict(\n        orientation=\"h\",\n        yanchor=\"bottom\",\n        y=1.02,\n        xanchor=\"right\",\n        x=1\n    ),\n    margin=dict(l=20, r=20, b=20, t=60)\n)\n\nfig.show()\n\n\n\n                                                \n\n\n\n                                                \n\n\n\n                                                \n\n\n\n\n2D PCA\nWhen conducting a 2D PCA analysis for all scenarios, the overall trend indicates that within each scenario, PCA1 primarily influences the data points. In contrast, between different scenarios, PCA2 is the key differentiator.\nWhat does that mean? The features that predominantly affect PCA1 are VWC (Volumetric Water Content in soil) and SWA (Soil Water Availability). This suggests that changes in these variables have the most significant impact within each scenario, reflecting variations over time or different years.\nOn the other hand, the features that most influence PCA2 are transpiration, the correlation between temperature and precipitation, evaporation, and the number of wet soil days. These features appear to distinguish between different scenarios, implying that they are critical in influencing temperature predictions.\nBut is this the case for scenario 37 and 40? As shown in the second plot, we can see that neigher PCA 1 nor PCA2 can identify a pattern in which the two scenarios are divided.\nWe could guess that scenario 37 eigher has a higher PCA2 or has both a lower PCA2 and PCA1, and scenario 40 seems to be somewhere in between the two groups of scenario 37.\nWe’ll add a third component to our analysis to see if we can gain any additional insight.\n\n\n2D PCA Plots\n# Visualize the results with Plotly\nfig = px.scatter(\n    data,\n    x='PCA1',\n    y='PCA2',\n    color='scenario',\n    title='&lt;b&gt;PCA For All Scenarios (RCP = 4.5)&lt;/b&gt;',\n    labels={'PCA1': 'PCA1', 'PCA2': 'PCA2'},\n    opacity=0.5\n)\n\nfig.update_layout(\n    margin=dict(l=10, r=10, b=10, t=40),  # Adjust the values as needed\n    title_x=0.5,\n    title_y=0.95,\n)\n\nfig.show()\n\nfig = px.scatter(\n    data[data['scenario'].isin(['sc37','sc40'])],\n    x='PCA1',\n    y='PCA2',\n    color='scenario',\n    title='&lt;b&gt;PCA for Scenario 37 vs 40 (RCP = 4.5)&lt;/b&gt;',\n    labels={'PCA1': 'PCA1', 'PCA2': 'PCA2'},\n    opacity=0.5\n)\n\nfig.update_layout(\n    margin=dict(l=10, r=10, b=10, t=40),  # Adjust the values as needed\n    title_x=0.5,\n    title_y=0.95,\n)\n\nfig.show()\n\n\n\n                                                \n\n\n\n                                                \n\n\n\n\n3D PCA\nWhat type of information can we retrieve from the third PCA that we couldn’t from the 2D PCA plot?\nJust by looking at the first plot with all scenarios, we can tell that the third PCA is also an important component when differentiating scenarios.\nHow about scenario 37 and 40? We’ve found the visualization we were looking for! PCA3 seems to be the best component to distinguish the two scenarios which had the most differentiation.\nWhat does this mean? Note that 37 had the highest temperature and 40 had the lowest temperature from RCP 4.5. Since scenario 37 can be distinguished with the points with the higher values of PCA3, we can look at the feature importance chart for PCA3 where the positive top ranked features would mean that an increase in the feature means higher temperature and lower values of the negative features mean higher temperature, and the opposite would apply for scenario 40.\nResults Unfortunately, the highest ranked features for PCA3 are mostly directly related to the temperature or variables that can’t seem to be altered for future improvement such as frost days, evaporation, and southness. One fact we can takeaway is that the PET or potential evapotranspiration which is a factor we can prevent or make higher with future efforts. The lower the potential evapotranspiration, the higher the temperature.\n\n\n3D PCA Plots\n# Visualize the results with Plotly in 3D\nfig = px.scatter_3d(\n    data,\n    x='PCA1',\n    y='PCA2',\n    z='PCA3',\n    color='scenario',\n    title='&lt;b&gt;3D PCA For All Scenarios&lt;/b&gt;',\n    labels={'PCA1': 'PCA1', 'PCA2': 'PCA2', 'PCA3': 'PCA3'},\n    opacity=0.5,\n    size_max=0.1\n)\n\nfig.update_traces(marker=dict(size=3))  # Adjust the size value as needed\n\n\n# Update layout to adjust padding and margins\nfig.update_layout(\n    margin=dict(l=5, r=5, b=5, t=20),  # Adjust the values as needed\n    title_x=0.5,\n    title_y=0.95,\n    scene=dict(\n        xaxis=dict(title='PCA1'),\n        yaxis=dict(title='PCA2'),\n        zaxis=dict(title='PCA3'),\n                camera=dict(\n            eye=dict(x=0, y=2, z=0)\n                )\n    )\n)\nfig.show()\n\nfig = px.scatter_3d(\n    data[data['scenario'].isin(['sc37','sc40'])],\n    x='PCA1',\n    y='PCA2',\n    z='PCA3',\n    color='scenario',\n    title='&lt;b&gt;3D PCA for Scenario 37 vs 40&lt;/b&gt;',\n    labels={'PCA1': 'PCA1', 'PCA2': 'PCA2', 'PCA3': 'PCA3'},\n    opacity=0.5,\n    size_max=0.1\n)\n\nfig.update_traces(marker=dict(size=3))  # Adjust the size value as needed\n\n\n# Update layout to adjust padding and margins\nfig.update_layout(\n    margin=dict(l=5, r=5, b=5, t=20),  # Adjust the values as needed\n    title_x=0.5,\n    title_y=0.95,\n    scene=dict(\n        xaxis=dict(title='PCA1'),\n        yaxis=dict(title='PCA2'),\n        zaxis=dict(title='PCA3'),\n                camera=dict(\n            eye=dict(x=0, y=2, z=0)\n                )\n    )\n)\nfig.show()"
  },
  {
    "objectID": "Analysis.html#rmse",
    "href": "Analysis.html#rmse",
    "title": "Dataset Analysis",
    "section": "RMSE",
    "text": "RMSE\nTo identify the most significant differences between two scenarios, I employed another method: calculating the RMSE (Root Mean Square Error) for each column. Given that both scenarios have the same number of data points, this approach provided an effective way to quantify the differences. Before performing the RMSE calculations, I standardized the data points to ensure consistency.\nWhat was particularly interesting is that the features identified as “most different” by the RMSE method were distinct from those highlighted by Pearson correlation and PCA. Despite this, all three methods pointed in the same general direction. In addition to temperature and precipitation, the RMSE method revealed that a series of wet soil days, volumetric water content, and soil water availability showed significant differences between the scenarios. This highlighted how different methods can provide varied insights while still aligning on key differences.\n\n\nRMSE\nsc37 = df_orig[df_orig['scenario'] == 'sc37']\nsc40 = df_orig[df_orig['scenario'] == 'sc40']\n\ndf1 = sc37.iloc[:,8:-3]\ndf2 = sc40.iloc[:,8:-3]\n\n# Function to calculate z-scores\ndef standardize(df):\n    return df.apply(zscore)\n\n# Standardize both dataframes\nz_df1 = standardize(df1)\nz_df2 = standardize(df2)\n\n# Calculate Absolute Difference of Z-Scores\nabs_diff_z_scores = np.abs(z_df1 - z_df2)\n\n# Mean Absolute Difference\nmean_abs_diff = abs_diff_z_scores.mean()\n\n# RMSE\nrmse = np.sqrt(np.mean((z_df1.reset_index(drop=True) - z_df2.reset_index(drop=True))**2, axis=0))\n\nrmse_sort = rmse.sort_values(ascending=False).head(30)\n\n# Create a bar chart\nfig = go.Figure(data=[go.Bar(\n    x=rmse_sort.keys(),\n    y=rmse_sort.values,\n    text=[round(i,4) for i in rmse_sort.values],  # Show the actual values as text\n    textposition='inside',\n    # marker_color=colors,\n    showlegend=False\n)])\n\n# Update layout for better readability\nfig.update_layout(\n    title='&lt;b&gt;Scenario 37 vs 40 RMSE of components&lt;/b&gt;',\n    xaxis_title='Features',\n    yaxis_title='Absolute PCA1 Loadings',\n    yaxis=dict(tickformat=\".2f\"),\n    template='plotly_white',\n    legend=dict(\n        orientation=\"h\",\n        yanchor=\"bottom\",\n        y=1.02,\n        xanchor=\"right\",\n        x=1\n    ),\n    margin=dict(l=20, r=20, b=20, t=60)\n)\n\nfig.show()"
  },
  {
    "objectID": "Analysis.html#t-sne",
    "href": "Analysis.html#t-sne",
    "title": "Dataset Analysis",
    "section": "t-SNE",
    "text": "t-SNE\nWhat is t-SNE?\nt-SNE (t-distributed Stochastic Neighbor Embedding) is a dimensionality reduction technique particularly effective in visualizing high-dimensional data. It works by converting similarities between data points into joint probabilities and minimizing the Kullback-Leibler divergence between these joint probabilities in the high-dimensional and low-dimensional space. This results in a map where similar objects are modeled by nearby points and dissimilar objects by distant points. When interpreting a t-SNE plot, clusters indicate groups of similar data points, suggesting patterns or structures within the data. However, the distances between clusters and the exact positioning can sometimes be arbitrary, so the focus should be on the local neighborhood structures rather than global distances.\nAnalysis Methodology With a similar flow of analysis we conducted with the RCP = 4.5 scenario with PCA, we will first plot the 2D outcome of t-SNE and proceed to the 3D scatterplot.\nOne difference between PCA and t-SNE is that the values of components in PCA do not change no matter how many components are calculated, therefore the same feature importance plot could be applicable for any dimensionality. However, t-SNE gives different output from when 3 components are calculated and 2 components are calculated. Therefore separate feature importance plots are necessary to correctly interpret the outcome.\n\n2D t-SNE Plot\nThe analysis demonstrates that t-SNE effectively groups similar data points together, with distinct clusters representing unique scenario and year combinations. This clear grouping contrasts with PCA, which stretched data points across an axis to portray differences within a scenario. In comparing scenarios 60 and 58, the second plot shows most points are separated by the t-SNE1 axis. However, scenario 60’s data for the year 2098 overlaps with scenario 58, indicating that while t-SNE1 is generally effective in differentiating between the two scenarios, it has limitations.\nThe third plot highlights which features from the original dataframe correlate with the newly created t-SNE1 feature. It turns out that SWA (Soil Water Availability) and VWC (Volumetric Water Content) are the main variables correlating with t-SNE1. This finding differs from the PCA analysis with RCP4.5, where VWC and SWA were more involved in changes within scenarios rather than differentiating between them. However, the misclassification of scenario 60’s 2098 data suggests that t-SNE1 might not be entirely accurate for all data points.\nGiven these observations, moving to a 3D t-SNE analysis makes sense. By incorporating an additional dimension, 3D t-SNE could provide a more accurate and nuanced clustering of data points, potentially avoiding the misclassifications observed with just t-SNE1. This approach could lead to better separation and a clearer understanding of the relationships between different scenarios and years.\n\n\nt-SNE(RCP = 8.5)\ndata_1 = df_orig[(df_orig['RCP']==8.5) & (df_orig['year'].isin(range(2095,2100)))].dropna(axis=1, how='any')\nX = data.iloc[:,list(range(1, 3))+ list(range(8, len(data.columns)-3))]\ny = data.iloc[:,len(data.columns)-3]\n\n# Standardize the features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\nscaler = StandardScaler()\ny_scaled = pd.Series(scaler.fit_transform(y.values.reshape(-1,1)).flatten())\n\n# Perform t-SNE on the features\ntsne = TSNE(n_components=2, random_state=42)\ntsne_results = tsne.fit_transform(X_scaled)\n\ndata_1['tsne1'] = tsne_results[:, 0]\ndata_1['tsne2'] = tsne_results[:, 1]\n\n# Visualize the results with Plotly\nfig = px.scatter(\n    data_1,\n    x='tsne1',\n    y='tsne2',\n    color='scenario',\n    title='&lt;b&gt;t-SNE For All Scenarios (RCP = 8.5)&lt;/b&gt;',\n    labels={'tsne1': 't-SNE1', 'tsne2': 't-SNE2'},\n    opacity=0.5,\n    hover_data={'Location_ID': True, 'year':True}\n)\n\nfig.update_layout(\n    margin=dict(l=10, r=10, b=10, t=40),  # Adjust the values as needed\n    title_x=0.5,\n    title_y=0.95,\n)\n\nfig.show()\n\n# Visualize the results with Plotly\nfig = px.scatter(\n    data_1[data_1['scenario'].isin(['sc60','sc58'])],\n    x='tsne1',\n    y='tsne2',\n    color='scenario',\n    title='&lt;b&gt;t-SNE For Scenario 60 and 58 (RCP = 8.5)&lt;/b&gt;',\n    labels={'tsne1': 't-SNE1', 'tsne2': 't-SNE2'},\n    opacity=0.5,\n    hover_data={'Location_ID': True, 'year':True}\n)\n\nfig.update_layout(\n    margin=dict(l=10, r=10, b=10, t=40),  # Adjust the values as needed\n    title_x=0.5,\n    title_y=0.95,\n)\n\nfig.show()\n\n\n\n                                                \n\n\n\n                                                \n\n\n\n\nCode\ncorr_matrix = data_1.iloc[:,8:].corr()\n#| code-summary: Correlation Feature Importance\n\n# Sort the features by the absolute value of the loading for PCA1\nsorted_loadings_1 = corr_matrix['tsne1'].abs().sort_values(ascending=False)\ntop_features_1 = sorted_loadings_1.head(30).index\ntop_loadings_1 = round(corr_matrix['tsne1'].loc[top_features_1,],4)[1:]\ncolors_1 = ['blue' if val &gt; 0 else 'red' for val in top_loadings_1]\n\n# Create a bar chart\nfig = go.Figure(data=[go.Bar(\n    x=top_loadings_1.index,\n    y=top_loadings_1.abs(),\n    text=top_loadings_1.values,  # Show the actual values as text\n    textposition='inside',\n    marker_color=colors_1,\n    showlegend=False\n)])\n\n# Add legend manually\nfig.add_trace(go.Bar(\n    x=[None], y=[None],\n    marker=dict(color='blue'),\n    showlegend=True,\n    name='Positive'\n))\nfig.add_trace(go.Bar(\n    x=[None], y=[None],\n    marker=dict(color='red'),\n    showlegend=True,\n    name='Negative'\n))\n\n# Update layout for better readability\nfig.update_layout(\n    title='&lt;b&gt;Top Features Correlating to t-SNE1&lt;/b&gt;',\n    xaxis_title='Features',\n    yaxis_title='Absolute t-SNE1 Loadings',\n    yaxis=dict(tickformat=\".2f\"),\n    xaxis=dict(\n        tickangle=45,  # Rotate x ticks\n        tickfont=dict(size=10)  # Make the font smaller\n    ),\n    template='plotly_white',\n    legend=dict(\n        orientation=\"h\",\n        yanchor=\"bottom\",\n        y=1.02,\n        xanchor=\"right\",\n        x=1\n    ),\n    margin=dict(l=20, r=20, b=20, t=60)\n)\n\nfig.show()\n\n\n\n                                                \n\n\n\n\n3D t-SNE Plot\nTo understand the features that correlate most with t-SNE3, let’s follow a similar approach as we did with the PCA analysis. Here’s a structured plan to proceed with this analysis:\n\nPlotting all Scenarios using 3D t-SNE:\n\nGenerate a 3D scatter plot of all scenarios using the t-SNE results. Color-code the points based on different scenarios to visualize clustering.\n\nComparison of Scenarios 60 and 58:\n\nCreate another 3D scatter plot but include only scenarios 60 and 58.\nObserve the separation between these two scenarios on the t-SNE3 axis and determine the effectiveness of a decision boundary.\n\nCorrelating Features with t-SNE3:\n\nCalculate the correlation between each feature and t-SNE3.\nRank the features based on their correlation values.\n\nResults:\n\nLike our third component in PCA, t-SNE3 is mostly correlated by the seasonal temperatures directly, following with SA, Litter, S, SWA, Bare and Shrub.\n\n\n\n\n3D t-SNE (RCP = 8.5)\ndata = df_orig[(df_orig['RCP']==8.5) & (df_orig['year'].isin(range(2095,2100)))].dropna(axis=1, how='any')\nX = data.iloc[:,list(range(1, 3))+ list(range(8, len(data.columns)-3))]\ny = data.iloc[:,len(data.columns)-3]\n\n# Standardize the features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\nscaler = StandardScaler()\ny_scaled = pd.Series(scaler.fit_transform(y.values.reshape(-1,1)).flatten())\n\n# Perform t-SNE on the features\ntsne = TSNE(n_components=3, random_state=42)\ntsne_results = tsne.fit_transform(X_scaled)\n\ndata['tsne1'] = tsne_results[:, 0]\ndata['tsne2'] = tsne_results[:, 1]\ndata['tsne3'] = tsne_results[:, 2]\n\n# Visualize the results with Plotly in 3D\nfig = px.scatter_3d(\n    data,\n    x='tsne1',\n    y='tsne2',\n    z='tsne3',\n    color='scenario',\n    title='&lt;b&gt;3D t-SNE For All Scenarios&lt;/b&gt;',\n    labels={'tsne1': 't-SNE1', 'tsne2': 't-SNE2', 'tsne3': 't-SNE3'},\n    opacity=0.5,\n    size_max=0.1,\n    hover_data={'Location_ID': True, 'year': True}\n    \n)\n\nfig.update_traces(marker=dict(size=3))  # Adjust the size value as needed\n\n\n# Update layout to adjust padding and margins\nfig.update_layout(\n    margin=dict(l=5, r=5, b=5, t=20),  # Adjust the values as needed\n    title_x=0.5,\n    title_y=0.95,\n    scene=dict(\n        xaxis=dict(title='t-SNE1'),\n        yaxis=dict(title='t-SNE2'),\n        zaxis=dict(title='t-SNE3'),\n                camera=dict(\n            eye=dict(x=2, y=0, z=0.1)\n                )\n    )\n)\nfig.show()\n\n# Visualize the results with Plotly in 3D\nfig = px.scatter_3d(\n    data[data['scenario'].isin(['sc60','sc58'])],\n    x='tsne1',\n    y='tsne2',\n    z='tsne3',\n    color='scenario',\n    title='&lt;b&gt;3D t-SNE For Scenario 60 and 58&lt;/b&gt;',\n    labels={'tsne1': 't-SNE1', 'tsne2': 't-SNE2', 'tsne3': 't-SNE3'},\n    opacity=0.5,\n    size_max=0.1,\n    hover_data={'Location_ID': True, 'year': True}\n    \n)\n\nfig.update_traces(marker=dict(size=3))  # Adjust the size value as needed\n\n\n# Update layout to adjust padding and margins\nfig.update_layout(\n    margin=dict(l=5, r=5, b=5, t=20),  # Adjust the values as needed\n    title_x=0.5,\n    title_y=0.95,\n    scene=dict(\n        xaxis=dict(title='t-SNE1'),\n        yaxis=dict(title='t-SNE2'),\n        zaxis=dict(title='t-SNE3'),\n                camera=dict(\n            eye=dict(x=2, y=0, z=0.1)\n                )\n    )\n)\nfig.show()\n\n\n\n                                                \n\n\n\n                                                \n\n\n\n\nt-SNE correlation(RCP=8.5)\ncorr_matrix = data.iloc[:,8:].corr()\n#| code-summary: Correlation Feature Importance\n\n# Sort the features by the absolute value of the loading for PCA1\nsorted_loadings_3 = corr_matrix['tsne3'].abs().sort_values(ascending=False)\ntop_features_3 = sorted_loadings_3.head(30).index\ntop_loadings_3 = round(corr_matrix['tsne3'].loc[top_features_3,],4)[1:]\ncolors_3 = ['blue' if val &gt; 0 else 'red' for val in top_loadings_3]\n\nsorted_loadings_2 = corr_matrix['tsne2'].abs().sort_values(ascending=False)\ntop_features_2 = sorted_loadings_2.head(30).index\ntop_loadings_2 = round(corr_matrix['tsne2'].loc[top_features_2,],4)[1:]\ncolors_2 = ['blue' if val &gt; 0 else 'red' for val in top_loadings_2]\n\nsorted_loadings_1 = corr_matrix['tsne1'].abs().sort_values(ascending=False)\ntop_features_1 = sorted_loadings_1.head(30).index\ntop_loadings_1 = round(corr_matrix['tsne1'].loc[top_features_1,],4)[1:]\ncolors_1 = ['blue' if val &gt; 0 else 'red' for val in top_loadings_1]\n\n# Create a bar chart\nfig = go.Figure(data=[go.Bar(\n    x=top_loadings_3.index,\n    y=top_loadings_3.abs(),\n    text=top_loadings_3.values,  # Show the actual values as text\n    textposition='inside',\n    marker_color=colors_3,\n    showlegend=False\n)])\n\n# Add legend manually\nfig.add_trace(go.Bar(\n    x=[None], y=[None],\n    marker=dict(color='blue'),\n    showlegend=True,\n    name='Positive'\n))\nfig.add_trace(go.Bar(\n    x=[None], y=[None],\n    marker=dict(color='red'),\n    showlegend=True,\n    name='Negative'\n))\n\n# Update layout for better readability\nfig.update_layout(\n    title='&lt;b&gt;Top Features Correlating to t-SNE3&lt;/b&gt;',\n    xaxis_title='Features',\n    yaxis_title='Absolute t-SNE3 Loadings',\n    yaxis=dict(tickformat=\".2f\"),\n    xaxis=dict(\n        tickangle=45,  # Rotate x ticks\n        tickfont=dict(size=10)  # Make the font smaller\n    ),\n    template='plotly_white',\n    legend=dict(\n        orientation=\"h\",\n        yanchor=\"bottom\",\n        y=1.02,\n        xanchor=\"right\",\n        x=1\n    ),\n    margin=dict(l=20, r=20, b=20, t=60)\n)\n\nfig.show()\n\n# Create a bar chart\nfig = go.Figure(data=[go.Bar(\n    x=top_loadings_2.index,\n    y=top_loadings_2.abs(),\n    text=top_loadings_2.values,  # Show the actual values as text\n    textposition='inside',\n    marker_color=colors_2,\n    showlegend=False\n)])\n\n# Add legend manually\nfig.add_trace(go.Bar(\n    x=[None], y=[None],\n    marker=dict(color='blue'),\n    showlegend=True,\n    name='Positive'\n))\nfig.add_trace(go.Bar(\n    x=[None], y=[None],\n    marker=dict(color='red'),\n    showlegend=True,\n    name='Negative'\n))\n\n# Update layout for better readability\nfig.update_layout(\n    title='&lt;b&gt;Top Features Correlating to t-SNE2&lt;/b&gt;',\n    xaxis_title='Features',\n    yaxis_title='Absolute t-SNE2 Loadings',\n    yaxis=dict(tickformat=\".2f\"),\n    xaxis=dict(\n        tickangle=45,  # Rotate x ticks\n        tickfont=dict(size=10)  # Make the font smaller\n    ),\n    template='plotly_white',\n    legend=dict(\n        orientation=\"h\",\n        yanchor=\"bottom\",\n        y=1.02,\n        xanchor=\"right\",\n        x=1\n    ),\n    margin=dict(l=20, r=20, b=20, t=60)\n)\n\nfig.show()"
  },
  {
    "objectID": "Analysis.html#rmse-1",
    "href": "Analysis.html#rmse-1",
    "title": "Dataset Analysis",
    "section": "RMSE",
    "text": "RMSE\nAlthough there are minor differences, the RMSE between the same columns of different scenarios were similar to the comparison in the RCP 4.5 scenario. This was somewhat called for since numbers were generated by a simulator following a certain logic.\n\n\nRMSE\nsc60 = df_orig[df_orig['scenario'] == 'sc60']\nsc58 = df_orig[df_orig['scenario'] == 'sc58']\n\ndf1 = sc60.iloc[:,8:-3]\ndf2 = sc58.iloc[:,8:-3]\n\n# Function to calculate z-scores\ndef standardize(df):\n    return df.apply(zscore)\n\n# Standardize both dataframes\nz_df1 = standardize(df1)\nz_df2 = standardize(df2)\n\n# Calculate Absolute Difference of Z-Scores\nabs_diff_z_scores = np.abs(z_df1 - z_df2)\n\n# Mean Absolute Difference\nmean_abs_diff = abs_diff_z_scores.mean()\n\n# RMSE\nrmse = np.sqrt(np.mean((z_df1.reset_index(drop=True) - z_df2.reset_index(drop=True))**2, axis=0))\n\nrmse_sort = rmse.sort_values(ascending=False).head(30)\n\n# Create a bar chart\nfig = go.Figure(data=[go.Bar(\n    x=rmse_sort.keys(),\n    y=rmse_sort.values,\n    text=[round(i,4) for i in rmse_sort.values],  # Show the actual values as text\n    textposition='inside',\n    # marker_color=colors,\n    showlegend=False\n)])\n\n# Update layout for better readability\nfig.update_layout(\n    title='&lt;b&gt;Scenario 60 vs 80 RMSE of components&lt;/b&gt;',\n    xaxis_title='Features',\n    yaxis_title='Absolute PCA1 Loadings',\n    yaxis=dict(tickformat=\".2f\"),\n    template='plotly_white',\n    legend=dict(\n        orientation=\"h\",\n        yanchor=\"bottom\",\n        y=1.02,\n        xanchor=\"right\",\n        x=1\n    ),\n    margin=dict(l=20, r=20, b=20, t=60)\n)\n\nfig.show()"
  },
  {
    "objectID": "EDA.html",
    "href": "EDA.html",
    "title": "Dataset EDA",
    "section": "",
    "text": "Import module / Set options and theme\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport xml.etree.ElementTree as ET\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom scipy.stats import ttest_rel\nfrom statsmodels.stats.weightstats import ttest_ind\nimport numpy as np\nimport pingouin as pg\nfrom scipy.stats import zscore\nimport plotly.graph_objects as go\nimport pandas as pd\nfrom plotly.subplots import make_subplots\nimport warnings\nimport numpy as np\nimport pandas as pd\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\n\nwarnings.filterwarnings(\"ignore\")\n\npd.set_option('display.max_columns', None)\npd.set_option('display.precision', 10)\nImport cleaned data\ndf = pd.read_csv('../data/cleaned_df.csv')\ndf['Location_ID'] = df.groupby(['long', 'lat']).ngroup() + 1"
  },
  {
    "objectID": "EDA.html#average-scenarios",
    "href": "EDA.html#average-scenarios",
    "title": "Dataset EDA",
    "section": "Average Scenarios",
    "text": "Average Scenarios\nThe Average Scenarios dataset averages all the numerical columns of the scenarios into one row, outputing one row for each Location, Year, and RCP. This dataset is used when conducting EDA and visualizing overtrend\n\n\nClean data (Average Scenarios)\ngroup_list = ['Park', 'long', 'lat', 'veg', 'year', 'TimePeriod', 'RCP','treecanopy', 'Ann_Herb', 'Bare', 'Herb', 'Litter', 'Shrub', 'El', 'Sa','Cl', 'RF', 'Slope', 'E', 'S']\nveg_location = df.drop(labels='scenario',axis=1).groupby(group_list).mean().reset_index()\n# veg_location['T_Annual'] = (veg_location['T_Annual'] - veg_location['T_Annual'].min()) / (veg_location['T_Annual'].max() - veg_location['T_Annual'].min())\n\n# Convert to numeric, coercing errors to NaN\nnumeric_series = pd.to_numeric(veg_location['RCP'], errors='coerce')\n\nnumeric_series\n\n# Fill NaNs with original non-numeric values\nveg_location['RCP'] = numeric_series.fillna(veg_location['RCP'])\n\nfour = veg_location[veg_location['RCP'].isin([4.5])]\neight = veg_location[veg_location['RCP'].isin([8.5])]\nfour_h = veg_location[veg_location['RCP'].isin(['historical'])]\nfour_h['RCP'] = 4.5\neight_h = veg_location[veg_location['RCP'].isin(['historical'])]\neight_h['RCP'] = 8.5\n\ndf_con = pd.concat([four_h, four, eight_h, eight], ignore_index=True)\ndf_con['Location_ID'] = df_con.groupby(['long', 'lat']).ngroup() + 1\n\ndf_con.head(5)\n\n\n\n\n\n\n\n\n\nPark\nlong\nlat\nveg\nyear\nTimePeriod\nRCP\ntreecanopy\nAnn_Herb\nBare\nHerb\nLitter\nShrub\nEl\nSa\nCl\nRF\nSlope\nE\nS\nT_P_Corr\nDrySoilDays_Winter_top50\nDrySoilDays_Spring_top50\nDrySoilDays_Summer_top50\nDrySoilDays_Fall_top50\nDrySoilDays_Winter_whole\nDrySoilDays_Spring_whole\nDrySoilDays_Summer_whole\nDrySoilDays_Fall_whole\nEvap_Winter\nEvap_Spring\nEvap_Summer\nEvap_Fall\nExtremeShortTermDryStress_Winter_top50\nExtremeShortTermDryStress_Spring_top50\nExtremeShortTermDryStress_Summer_top50\nExtremeShortTermDryStress_Fall_top50\nExtremeShortTermDryStress_Winter_whole\nExtremeShortTermDryStress_Spring_whole\nExtremeShortTermDryStress_Summer_whole\nExtremeShortTermDryStress_Fall_whole\nFrostDays_Winter\nFrostDays_Spring\nFrostDays_Summer\nFrostDays_Fall\nNonDrySWA_Winter_top50\nNonDrySWA_Spring_top50\nNonDrySWA_Summer_top50\nNonDrySWA_Fall_top50\nNonDrySWA_Winter_whole\nNonDrySWA_Spring_whole\nNonDrySWA_Summer_whole\nNonDrySWA_Fall_whole\nPET_Winter\nPET_Spring\nPET_Summer\nPET_Fall\nPPT_Winter\nPPT_Spring\nPPT_Summer\nPPT_Fall\nSemiDryDuration_Annual_top50\nSemiDryDuration_Annual_whole\nSWA_Winter_top50\nSWA_Spring_top50\nSWA_Summer_top50\nSWA_Fall_top50\nSWA_Winter_whole\nSWA_Spring_whole\nSWA_Summer_whole\nSWA_Fall_whole\nT_Winter\nT_Spring\nT_Summer\nT_Fall\nTmax_Winter\nTmax_Spring\nTmax_Summer\nTmax_Fall\nTmin_Winter\nTmin_Spring\nTmin_Summer\nTmin_Fall\nTransp_Winter\nTransp_Spring\nTransp_Summer\nTransp_Fall\nVWC_Winter_top50\nVWC_Spring_top50\nVWC_Summer_top50\nVWC_Fall_top50\nVWC_Winter_whole\nVWC_Spring_whole\nVWC_Summer_whole\nVWC_Fall_whole\nWetSoilDays_Winter_top50\nWetSoilDays_Spring_top50\nWetSoilDays_Summer_top50\nWetSoilDays_Fall_top50\nWetSoilDays_Winter_whole\nWetSoilDays_Spring_whole\nWetSoilDays_Summer_whole\nWetSoilDays_Fall_whole\nPPT_Annual\nT_Annual\nRL\nLocation_ID\n\n\n\n\n0\nNABR\n-110.0472\n37.60413\nShrubland\n1980\nHist\n4.5\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n1949.283\n-8753.784\n4834.13\n-0.6636760860\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n3.7140658366\n6.3995308949\n1.5598074021\n3.3632779979\nNaN\n24.34\n36.16\n29.52\nNaN\n24.34\n36.16\n29.52\n75.0\n34.0\n0.0\n26.0\n3.4668806371\n2.6546632530\n0.0321140671\n0.4880867481\n3.4668806371\n2.6546632530\n0.0321140671\n0.4880867481\n7.7811633032\n31.1394527955\n48.0177480655\n21.9156825756\n13.79\n8.71\n2.69\n6.37\n36.5000000000\n36.5000000000\n3.4668806371\n2.6546632530\n0.0321140671\n0.4880867481\n3.4668806371\n2.6546632530\n0.0321140671\n0.4880867481\n0.96483520\n8.767935\n23.15924\n11.962090\n14.15\n28.75\n37.05\n31.15\n-12.45\n-7.35\n5.55\n-10.25\n0.2370806\n5.296833\n1.067496\n1.9667860\n0.1134468701\n0.0968307001\n0.0418759016\n0.0522975530\n0.1134468701\n0.0968307001\n0.0418759016\n0.0522975530\n91.0\n77.0\n5.0\n47.0\n91.0\n77.0\n5.0\n47.0\n31.56\n11.21352505\n54.57202074\n1\n\n\n1\nNABR\n-110.0472\n37.60413\nShrubland\n1981\nHist\n4.5\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n1949.283\n-8753.784\n4834.13\n0.3478010620\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n2.1815202084\n5.9723378265\n5.0428776741\n4.6374034668\n13.92\n26.53\n36.08\nNaN\n13.92\n26.53\n36.08\nNaN\n79.0\n26.0\n0.0\n13.0\n0.3461917264\n0.8982752558\n0.0336629893\n2.5013360811\n0.3461917264\n0.8982752558\n0.0336629893\n2.5013360811\n8.1229049607\n32.3882557036\n48.1772426406\n21.7575735702\n2.25\n9.81\n9.39\n11.75\n13.2500000000\n13.2500000000\n0.3461917264\n0.8982752558\n0.0336629893\n2.5013360811\n0.3461917264\n0.8982752558\n0.0336629893\n2.5013360811\n3.33444400\n10.548370\n23.27065\n11.581320\n17.05\n28.15\n37.55\n29.75\n-9.35\n-5.55\n1.25\n-7.25\n0.2930753\n3.506108\n3.916328\n2.7875470\n0.0493818430\n0.0607271763\n0.0426386771\n0.0936706801\n0.0493818430\n0.0607271763\n0.0426386771\n0.0936706801\n48.0\n60.0\n13.0\n85.0\n48.0\n60.0\n13.0\n85.0\n33.20\n12.18369600\n54.57202074\n1\n\n\n2\nNABR\n-110.0472\n37.60413\nShrubland\n1982\nHist\n4.5\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n1949.283\n-8753.784\n4834.13\n0.3260300992\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n3.2589947135\n4.7173273934\n4.5276363327\n4.2477717540\nNaN\n26.19\n34.99\n22.06\nNaN\n26.19\n34.99\n22.06\n83.0\n21.0\n0.0\n30.0\n3.2599844936\n1.5994982052\n0.1993822366\n1.2432253150\n3.2599844936\n1.5994982052\n0.1993822366\n1.2432253150\n7.3379526955\n31.4894498184\n47.1800768757\n21.0684231651\n4.12\n5.10\n9.50\n9.83\n17.2857142857\n17.2857142857\n3.2599844936\n1.5994982052\n0.1993822366\n1.2432253150\n3.2599844936\n1.5994982052\n0.1993822366\n1.2432253150\n-0.01555556\n9.472283\n22.05707\n9.869231\n14.35\n28.45\n36.65\n31.85\n-16.55\n-7.25\n5.65\n-6.25\n0.2453347\n3.105047\n3.523923\n2.8900990\n0.1092341982\n0.0748166564\n0.0456102615\n0.0677891794\n0.1092341982\n0.0748166564\n0.0456102615\n0.0677891794\n90.0\n62.0\n19.0\n73.0\n90.0\n62.0\n19.0\n73.0\n28.55\n10.34575711\n54.57202074\n1\n\n\n3\nNABR\n-110.0472\n37.60413\nShrubland\n1983\nHist\n4.5\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n1949.283\n-8753.784\n4834.13\n0.0388273872\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n3.7419915365\n6.2671578978\n5.1695757094\n3.7751048188\nNaN\n28.56\n33.69\n31.02\nNaN\n28.56\n33.69\n31.02\n85.0\n32.0\n0.0\n19.0\n3.8064480379\n2.9456592119\n0.0960442305\n1.5835966242\n3.8064480379\n2.9456592119\n0.0960442305\n1.5835966242\n7.4798456947\n30.3128312703\n46.5762368398\n21.8471460016\n7.09\n10.80\n10.22\n10.40\n16.7142857143\n16.7142857143\n3.8064480379\n2.9456592119\n0.0960442305\n1.5835966242\n3.8064480379\n2.9456592119\n0.0960442305\n1.5835966242\n0.40944440\n8.020652\n21.32826\n11.325820\n13.35\n30.65\n34.55\n33.15\n-15.05\n-7.25\n3.85\n-8.95\n0.2252735\n4.962824\n5.006576\n1.1952350\n0.1204177901\n0.1025422325\n0.0441405046\n0.0748017843\n0.1204177901\n0.1025422325\n0.0441405046\n0.0748017843\n90.0\n74.0\n15.0\n69.0\n90.0\n74.0\n15.0\n69.0\n38.51\n10.27104410\n54.57202074\n1\n\n\n4\nNABR\n-110.0472\n37.60413\nShrubland\n1984\nHist\n4.5\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n1949.283\n-8753.784\n4834.13\n0.2166602692\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n3.6272686835\n5.0078604793\n5.2303324404\n4.0803373430\nNaN\n30.95\n34.01\n29.52\nNaN\n30.95\n34.01\n29.52\n91.0\n35.0\n0.0\n30.0\n3.7945975224\n1.7555326024\n0.0452782946\n1.3792575946\n3.7945975224\n1.7555326024\n0.0452782946\n1.3792575946\n7.1730101555\n31.9972417196\n47.0386757592\n21.0183982059\n4.77\n4.32\n9.49\n8.17\n16.5000000000\n16.5000000000\n3.7945975224\n1.7555326024\n0.0452782946\n1.3792575946\n3.7945975224\n1.7555326024\n0.0452782946\n1.3792575946\n-1.04725300\n9.853804\n21.95978\n10.034070\n10.25\n32.75\n35.35\n31.35\n-18.45\n-8.45\n2.95\n-12.45\n0.1226868\n3.120243\n4.269040\n0.9273169\n0.1202091711\n0.0778415354\n0.0431793330\n0.0703661709\n0.1202091711\n0.0778415354\n0.0431793330\n0.0703661709\n91.0\n65.0\n16.0\n62.0\n91.0\n65.0\n16.0\n62.0\n26.75\n10.20010025\n54.57202074\n1"
  },
  {
    "objectID": "EDA.html#all-scenarios",
    "href": "EDA.html#all-scenarios",
    "title": "Dataset EDA",
    "section": "All Scenarios",
    "text": "All Scenarios\n\n\nCode\n# Convert to numeric, coercing errors to NaN\nnumeric_series = pd.to_numeric(df['RCP'], errors='coerce')\n\nnumeric_series\n\n# Fill NaNs with original non-numeric values\ndf['RCP'] = numeric_series.fillna(df['RCP'])\n\nfour = df[df['RCP'].isin([4.5])]\neight = df[df['RCP'].isin([8.5])]\nfour_h = df[df['RCP'].isin(['historical'])]\nfour_h['RCP'] = 4.5\neight_h = df[df['RCP'].isin(['historical'])]\neight_h['RCP'] = 8.5\n\ndf_orig = pd.concat([four_h, four, eight_h, eight], ignore_index=True)\ndf_orig['Location_ID'] = df_orig.groupby(['long', 'lat']).ngroup() + 1\n\ndf_orig.head(5)\n\n\n\n\n\n\n\n\n\nPark\nlong\nlat\nveg\nyear\nTimePeriod\nRCP\nscenario\ntreecanopy\nAnn_Herb\nBare\nHerb\nLitter\nShrub\nEl\nSa\nCl\nRF\nSlope\nE\nS\nT_P_Corr\nDrySoilDays_Winter_top50\nDrySoilDays_Spring_top50\nDrySoilDays_Summer_top50\nDrySoilDays_Fall_top50\nDrySoilDays_Winter_whole\nDrySoilDays_Spring_whole\nDrySoilDays_Summer_whole\nDrySoilDays_Fall_whole\nEvap_Winter\nEvap_Spring\nEvap_Summer\nEvap_Fall\nExtremeShortTermDryStress_Winter_top50\nExtremeShortTermDryStress_Spring_top50\nExtremeShortTermDryStress_Summer_top50\nExtremeShortTermDryStress_Fall_top50\nExtremeShortTermDryStress_Winter_whole\nExtremeShortTermDryStress_Spring_whole\nExtremeShortTermDryStress_Summer_whole\nExtremeShortTermDryStress_Fall_whole\nFrostDays_Winter\nFrostDays_Spring\nFrostDays_Summer\nFrostDays_Fall\nNonDrySWA_Winter_top50\nNonDrySWA_Spring_top50\nNonDrySWA_Summer_top50\nNonDrySWA_Fall_top50\nNonDrySWA_Winter_whole\nNonDrySWA_Spring_whole\nNonDrySWA_Summer_whole\nNonDrySWA_Fall_whole\nPET_Winter\nPET_Spring\nPET_Summer\nPET_Fall\nPPT_Winter\nPPT_Spring\nPPT_Summer\nPPT_Fall\nSemiDryDuration_Annual_top50\nSemiDryDuration_Annual_whole\nSWA_Winter_top50\nSWA_Spring_top50\nSWA_Summer_top50\nSWA_Fall_top50\nSWA_Winter_whole\nSWA_Spring_whole\nSWA_Summer_whole\nSWA_Fall_whole\nT_Winter\nT_Spring\nT_Summer\nT_Fall\nTmax_Winter\nTmax_Spring\nTmax_Summer\nTmax_Fall\nTmin_Winter\nTmin_Spring\nTmin_Summer\nTmin_Fall\nTransp_Winter\nTransp_Spring\nTransp_Summer\nTransp_Fall\nVWC_Winter_top50\nVWC_Spring_top50\nVWC_Summer_top50\nVWC_Fall_top50\nVWC_Winter_whole\nVWC_Spring_whole\nVWC_Summer_whole\nVWC_Fall_whole\nWetSoilDays_Winter_top50\nWetSoilDays_Spring_top50\nWetSoilDays_Summer_top50\nWetSoilDays_Fall_top50\nWetSoilDays_Winter_whole\nWetSoilDays_Spring_whole\nWetSoilDays_Summer_whole\nWetSoilDays_Fall_whole\nPPT_Annual\nT_Annual\nRL\nLocation_ID\n\n\n\n\n0\nNABR\n-110.0472\n37.60413\nShrubland\n1980\nHist\n4.5\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n1949.283\n-8753.784\n4834.13\n-0.6636760860\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n3.7140658366\n6.3995308949\n1.5598074021\n3.3632779979\nNaN\n24.34\n36.16\n29.52\nNaN\n24.34\n36.16\n29.52\n75.0\n34.0\n0.0\n26.0\n3.4668806371\n2.6546632530\n0.0321140671\n0.4880867481\n3.4668806371\n2.6546632530\n0.0321140671\n0.4880867481\n7.7811633032\n31.1394527955\n48.0177480655\n21.9156825756\n13.79\n8.71\n2.69\n6.37\n36.5000000000\n36.5000000000\n3.4668806371\n2.6546632530\n0.0321140671\n0.4880867481\n3.4668806371\n2.6546632530\n0.0321140671\n0.4880867481\n0.96483520\n8.767935\n23.15924\n11.962090\n14.15\n28.75\n37.05\n31.15\n-12.45\n-7.35\n5.55\n-10.25\n0.2370806\n5.296833\n1.067496\n1.9667860\n0.1134468701\n0.0968307001\n0.0418759016\n0.0522975530\n0.1134468701\n0.0968307001\n0.0418759016\n0.0522975530\n91.0\n77.0\n5.0\n47.0\n91.0\n77.0\n5.0\n47.0\n31.56\n11.21352505\n54.57202074\n1\n\n\n1\nNABR\n-110.0472\n37.60413\nShrubland\n1981\nHist\n4.5\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n1949.283\n-8753.784\n4834.13\n0.3478010620\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n2.1815202084\n5.9723378265\n5.0428776741\n4.6374034668\n13.92\n26.53\n36.08\nNaN\n13.92\n26.53\n36.08\nNaN\n79.0\n26.0\n0.0\n13.0\n0.3461917264\n0.8982752558\n0.0336629893\n2.5013360811\n0.3461917264\n0.8982752558\n0.0336629893\n2.5013360811\n8.1229049607\n32.3882557036\n48.1772426406\n21.7575735702\n2.25\n9.81\n9.39\n11.75\n13.2500000000\n13.2500000000\n0.3461917264\n0.8982752558\n0.0336629893\n2.5013360811\n0.3461917264\n0.8982752558\n0.0336629893\n2.5013360811\n3.33444400\n10.548370\n23.27065\n11.581320\n17.05\n28.15\n37.55\n29.75\n-9.35\n-5.55\n1.25\n-7.25\n0.2930753\n3.506108\n3.916328\n2.7875470\n0.0493818430\n0.0607271763\n0.0426386771\n0.0936706801\n0.0493818430\n0.0607271763\n0.0426386771\n0.0936706801\n48.0\n60.0\n13.0\n85.0\n48.0\n60.0\n13.0\n85.0\n33.20\n12.18369600\n54.57202074\n1\n\n\n2\nNABR\n-110.0472\n37.60413\nShrubland\n1982\nHist\n4.5\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n1949.283\n-8753.784\n4834.13\n0.3260300992\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n3.2589947135\n4.7173273934\n4.5276363327\n4.2477717540\nNaN\n26.19\n34.99\n22.06\nNaN\n26.19\n34.99\n22.06\n83.0\n21.0\n0.0\n30.0\n3.2599844936\n1.5994982052\n0.1993822366\n1.2432253150\n3.2599844936\n1.5994982052\n0.1993822366\n1.2432253150\n7.3379526955\n31.4894498184\n47.1800768757\n21.0684231651\n4.12\n5.10\n9.50\n9.83\n17.2857142857\n17.2857142857\n3.2599844936\n1.5994982052\n0.1993822366\n1.2432253150\n3.2599844936\n1.5994982052\n0.1993822366\n1.2432253150\n-0.01555556\n9.472283\n22.05707\n9.869231\n14.35\n28.45\n36.65\n31.85\n-16.55\n-7.25\n5.65\n-6.25\n0.2453347\n3.105047\n3.523923\n2.8900990\n0.1092341982\n0.0748166564\n0.0456102615\n0.0677891794\n0.1092341982\n0.0748166564\n0.0456102615\n0.0677891794\n90.0\n62.0\n19.0\n73.0\n90.0\n62.0\n19.0\n73.0\n28.55\n10.34575711\n54.57202074\n1\n\n\n3\nNABR\n-110.0472\n37.60413\nShrubland\n1983\nHist\n4.5\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n1949.283\n-8753.784\n4834.13\n0.0388273872\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n3.7419915365\n6.2671578978\n5.1695757094\n3.7751048188\nNaN\n28.56\n33.69\n31.02\nNaN\n28.56\n33.69\n31.02\n85.0\n32.0\n0.0\n19.0\n3.8064480379\n2.9456592119\n0.0960442305\n1.5835966242\n3.8064480379\n2.9456592119\n0.0960442305\n1.5835966242\n7.4798456947\n30.3128312703\n46.5762368398\n21.8471460016\n7.09\n10.80\n10.22\n10.40\n16.7142857143\n16.7142857143\n3.8064480379\n2.9456592119\n0.0960442305\n1.5835966242\n3.8064480379\n2.9456592119\n0.0960442305\n1.5835966242\n0.40944440\n8.020652\n21.32826\n11.325820\n13.35\n30.65\n34.55\n33.15\n-15.05\n-7.25\n3.85\n-8.95\n0.2252735\n4.962824\n5.006576\n1.1952350\n0.1204177901\n0.1025422325\n0.0441405046\n0.0748017843\n0.1204177901\n0.1025422325\n0.0441405046\n0.0748017843\n90.0\n74.0\n15.0\n69.0\n90.0\n74.0\n15.0\n69.0\n38.51\n10.27104410\n54.57202074\n1\n\n\n4\nNABR\n-110.0472\n37.60413\nShrubland\n1984\nHist\n4.5\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n1949.283\n-8753.784\n4834.13\n0.2166602692\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n3.6272686835\n5.0078604793\n5.2303324404\n4.0803373430\nNaN\n30.95\n34.01\n29.52\nNaN\n30.95\n34.01\n29.52\n91.0\n35.0\n0.0\n30.0\n3.7945975224\n1.7555326024\n0.0452782946\n1.3792575946\n3.7945975224\n1.7555326024\n0.0452782946\n1.3792575946\n7.1730101555\n31.9972417196\n47.0386757592\n21.0183982059\n4.77\n4.32\n9.49\n8.17\n16.5000000000\n16.5000000000\n3.7945975224\n1.7555326024\n0.0452782946\n1.3792575946\n3.7945975224\n1.7555326024\n0.0452782946\n1.3792575946\n-1.04725300\n9.853804\n21.95978\n10.034070\n10.25\n32.75\n35.35\n31.35\n-18.45\n-8.45\n2.95\n-12.45\n0.1226868\n3.120243\n4.269040\n0.9273169\n0.1202091711\n0.0778415354\n0.0431793330\n0.0703661709\n0.1202091711\n0.0778415354\n0.0431793330\n0.0703661709\n91.0\n65.0\n16.0\n62.0\n91.0\n65.0\n16.0\n62.0\n26.75\n10.20010025\n54.57202074\n1"
  },
  {
    "objectID": "EDA.html#basic-statistics",
    "href": "EDA.html#basic-statistics",
    "title": "Dataset EDA",
    "section": "Basic Statistics",
    "text": "Basic Statistics\nBasic Statistics\n\n79 years of prediction (2021~2099)\n40 scenarios (sc22~sc61)\n2 RCP scenarios(4.5, 8.5)\n113 locations\n\nExplanation\n\nThe data is collected over 113 locations within the Natural Bridge National Monument. (Number of Unique latitude, longitude combinations)\nThis dataset is composed of 41 years of historical data and 79 years worth of predictions. Since there can be only one scenario for past data, all historical data is labeled as ‘sc1’ or scenario one\nFrom the predicted years (2021 to 2099), There are two RCP scenarios which changes only the RCP variable and 40 scenarios which simulate 86 other variables.\n\nBased on each combination of scenarios, a prediction is made for each location point regarding various columns of the dataset including annual and seasonal percipitation, seasonal dry soil days, seasonal evaporation, seasonal extreme short term dry stress, soil water availability to output a final prediction for Annual and seasonal temperatures.\nWhat is RCP?\nRepresentative Concentration Pathways : A group of scenarios where CO2 emmission is predicted like the image below\n\nThe dataset consists of two RCP scenarios 4.5 and 8.5\n\n\nsource : Representative Concentration Pathway. (2024, May 2). In Wikipedia. https://en.wikipedia.org/wiki/Representative_Concentration_Pathway"
  },
  {
    "objectID": "EDA.html#location",
    "href": "EDA.html#location",
    "title": "Dataset EDA",
    "section": "Location",
    "text": "Location\nWhere is this data located and how does it look like?\nThe data points were sampled at the Natural Bridge National Monument in Utah. And for a better idea of The plots below show two different location aspects of the dataset. The first plot is the average annual temperature for each location point in the year 2099. Since the temperature for predictions increase over time, the last year for the dataset was chosen for a more dramatic comparison\nThe second plot is a scatter plot of the locations of vegetations. By comparing the two graphs, we can tell that there isn’t much correlation with vegetation and annual temperature but rather a correlation with the location(latitude, longitude) and temperature. We will get to this in the following visualizations.\n\n\nMap Visualizations\nmap = df_con[df_con['year']==2099].groupby(['long','lat'])['T_Annual'].mean().reset_index()\n\nfiltered_df = map\nfig = px.scatter_mapbox(filtered_df, lat=\"lat\", lon=\"long\", color=\"T_Annual\", size=\"T_Annual\",\n                  color_continuous_scale=px.colors.cyclical.IceFire, size_max=8, zoom=11,\n                  mapbox_style=\"open-street-map\")\n\nfig.update_layout(\n    title={\n        'text': \"&lt;b&gt;Average Temperature (2099) &lt;/b&gt;\",\n        'y': 0.97,\n        'x': 0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'\n    },\n    margin={\"r\": 0, \"t\": 40, \"l\": 0, \"b\": 0}\n    )\n\nfig.show()\n\nmap = df_con[df_con['year']==2099].groupby(['long','lat','veg']).size().reset_index()\n\nfiltered_df = map\n\n# Create the scatter mapbox\nfig = px.scatter_mapbox(map, lat=\"lat\", lon=\"long\", color=\"veg\",\n                        color_continuous_scale=px.colors.cyclical.IceFire, size_max=8, zoom=11,\n                        mapbox_style=\"open-street-map\")\n\n# Update the layout with the new legend title and position\nfig.update_layout(\n    title={\n        'text': \"&lt;b&gt;Vegetation Location&lt;/b&gt;\",\n        'y': 0.97,\n        'x': 0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'\n    },\n    coloraxis_colorbar={\n        'title': 'Vegetation Level'  # Change this to your desired legend title\n    },\n    legend={\n        'x': 1,  # Position the legend to the right\n        'y': 0.8,  # Center the legend vertically\n        'xanchor': 'left',  # Anchor the legend's x position to the left side\n        'yanchor': 'middle'  # Anchor the legend's y position to the middle\n    },\n    margin={\"r\": 0, \"t\": 40, \"l\": 0, \"b\": 0}\n)\nfig.update_traces(marker=dict(size=10))  # Set the desired fixed marker size\n\n# Show the figure\nfig.show()"
  },
  {
    "objectID": "EDA.html#temperaturepercipitation-trends",
    "href": "EDA.html#temperaturepercipitation-trends",
    "title": "Dataset EDA",
    "section": "Temperature/Percipitation Trends",
    "text": "Temperature/Percipitation Trends\nThe following plots were drawn by averaging all scenarios, locations, and RCPs for a given year for annual temperature and annual percipitation to see the overall trend of the predictions of the dataset. Predictions were made from the year 2021 which is\nWe can see that the predictions portray an increase in temperature but a fluctuation with percipitation allowing us to make an educated guess that temperature is the more important variable for RCP scenarios which deal with CO2 emission.\n\n\nTemperature / Percipitation Predictions Overview\n# Assuming 'veg_location' is your DataFrame\n# Filter the DataFrame for 'RCP' values 'historical' and 4.5\nfiltered_data = df_con.groupby(['year'])['T_Annual'].mean().reset_index()\n\n# Create the line plot\nfig = px.line(\n    data_frame=filtered_data,\n    x='year',\n    y='T_Annual',\n    title='&lt;b&gt;Annual Temperature&lt;/b&gt;',\n    labels={'T_Annual': 'Annual Temperature'},\n    line_shape='spline'\n)\n\n# Add a vertical line at year 2021\nfig.add_shape(\n    dict(\n        type='line',\n        x0=2021,\n        y0=filtered_data['T_Annual'].min()/1.1,\n        x1=2021,\n        y1=filtered_data['T_Annual'].max()*1.1,\n        line=dict(\n            color=\"Red\",\n            width=2,\n            dash=\"dash\",\n        ),\n    )\n)\n\nfig.add_annotation(\n    dict(\n        x=2021,  # Position the text to the right of the line\n        y=filtered_data['T_Annual'].max(),  # Position the text at the middle of the y-axis\n        xref=\"x\",\n        yref=\"y\",\n        text=\"Prediction\",\n        showarrow=False,\n        font=dict(\n            size=12,\n            color=\"Red\"\n        ),\n        align=\"center\",\n        xanchor=\"left\"\n    )\n)\n\nfig.update_layout(title={'x':0.5})\n# Show the plot\nfig.show()\n\n\n# Assuming 'veg_location' is your DataFrame\n# Filter the DataFrame for 'RCP' values 'historical' and 4.5\nfiltered_data = df_con.groupby(['year'])['PPT_Annual'].mean().reset_index()\n\n# Create the line plot\nfig = px.line(\n    data_frame=filtered_data,\n    x='year',\n    y='PPT_Annual',\n    title='&lt;b&gt;Annual Precipitation&lt;/b&gt;',\n    labels={'T_Annual': 'Annual Temperature'},\n    line_shape='spline'\n)\n\n# Add a vertical line at year 2021\nfig.add_shape(\n    dict(\n        type='line',\n        x0=2021,\n        y0=filtered_data['PPT_Annual'].min()/1.1,\n        x1=2021,\n        y1=filtered_data['PPT_Annual'].max()*1.1,\n        line=dict(\n            color=\"Red\",\n            width=2,\n            dash=\"dash\",\n        ),\n    )\n)\n\nfig.add_annotation(\n    dict(\n        x=2021,  # Position the text to the right of the line\n        y=filtered_data['PPT_Annual'].max(),  # Position the text at the middle of the y-axis\n        xref=\"x\",\n        yref=\"y\",\n        text=\"Prediction\",\n        showarrow=False,\n        font=dict(\n            size=12,\n            color=\"Red\"\n        ),\n        align=\"center\",\n        xanchor=\"left\"\n    )\n)\n\nfig.update_layout(title={'x':0.5})\n# Show the plot\nfig.show()"
  }
]